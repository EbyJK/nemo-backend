{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Extraction & Prioritization Pipeline\n",
    "### Input: Email Summary Text → Structured, Ranked Task List\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Email Summary (str)\n",
    "      │\n",
    "      ├─► [1] Sentence Segmentation        (NLTK + bullet-aware splitter)\n",
    "      │\n",
    "      ├─► [2] Task Sentence Detection      (imperative heuristics + KPE confidence)\n",
    "      │\n",
    "      ├─► [3] NER — spaCy en_core_web_trf  (PERSON, ORG, DATE, TIME)\n",
    "      │         → feeds assignee sieve & deadline extractor\n",
    "      │\n",
    "      ├─► [4] KPE — KeyBERT + YAKE fallback\n",
    "      │         → action phrase refinement\n",
    "      │\n",
    "      ├─► [5] Action Span Construction     (verb-anchor + KPE overlay)\n",
    "      │         → multi-action splitting on compound sentences\n",
    "      │\n",
    "      ├─► [6] Deadline Normalization       (10-rule matcher → dateparser fallback)\n",
    "      │\n",
    "      └─► [7] Priority Scoring            (weighted formula, fully explainable)\n",
    "                deadline_proximity  × 0.35\n",
    "                urgency_lexicon     × 0.20\n",
    "                risk_lexicon        × 0.20\n",
    "                customer_impact     × 0.15\n",
    "                authority_cues      × 0.10\n",
    "                ─────────────────────────\n",
    "                → Low / Medium / High / Critical\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1 — Installs *(run once, then restart kernel)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All deps ready.  spaCy model: en_core_web_trf\n"
     ]
    }
   ],
   "source": [
    "import subprocess, sys\n",
    "\n",
    "pkgs = [\"spacy\", \"keybert\", \"yake\", \"sentence-transformers\", \"nltk\", \"dateparser\"]\n",
    "for p in pkgs:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", p])\n",
    "\n",
    "# spaCy model — transformer model preferred\n",
    "try:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_trf\", \"--quiet\"])\n",
    "    SPACY_MODEL = \"en_core_web_trf\"\n",
    "except Exception:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\", \"--quiet\"])\n",
    "    SPACY_MODEL = \"en_core_web_sm\"\n",
    "\n",
    "import nltk\n",
    "for r in [\"punkt\", \"punkt_tab\", \"stopwords\"]: nltk.download(r, quiet=True)\n",
    "\n",
    "print(f\"All deps ready.  spaCy model: {SPACY_MODEL}\")\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2 — Imports & Timezone Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy: en_core_web_trf  (transformer NER)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 345.39it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyBERT ready (all-MiniLM-L6-v2)\n",
      "YAKE ready (fallback KPE)\n",
      "dateparser ready\n",
      "\n",
      "All modules loaded.  IST now: 2026-02-20 14:41 IST\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import re, json, warnings\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ── IST timezone ─────────────────────────────────────────────────────────────\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "    IST = ZoneInfo(\"Asia/Kolkata\")\n",
    "except Exception:\n",
    "    IST = None\n",
    "\n",
    "def now_ist() -> datetime:\n",
    "    return datetime.now().astimezone(IST) if IST else datetime.now()\n",
    "\n",
    "def ensure_ist(dt: datetime) -> datetime:\n",
    "    if IST:\n",
    "        return dt.replace(tzinfo=IST) if dt.tzinfo is None else dt.astimezone(IST)\n",
    "    return dt\n",
    "\n",
    "def iso_ist(dt: Optional[datetime]) -> Optional[str]:\n",
    "    return ensure_ist(dt).isoformat(timespec=\"seconds\") if dt else None\n",
    "\n",
    "# ── spaCy ─────────────────────────────────────────────────────────────────────\n",
    "import spacy\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_trf\")\n",
    "    print(\"spaCy: en_core_web_trf  (transformer NER)\")\n",
    "except Exception:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"spaCy: en_core_web_sm  (statistical NER)\")\n",
    "\n",
    "'''\n",
    "trf: better at finding person tag (for assignee); bert (nn); more accurate;\n",
    "sm: better at finding org tag (for assignee); rule-based; less accurate;\n",
    "'''\n",
    "\n",
    "# ── KeyBERT ───────────────────────────────────────────────────────────────────\n",
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT(model=\"all-MiniLM-L6-v2\")\n",
    "print(\"KeyBERT ready (all-MiniLM-L6-v2)\")\n",
    "\n",
    "'''\n",
    "keybert:\n",
    "- understands semantic meaning using transformer embeddings to extract keywords relevant to a sentence.\n",
    "- model used is lightwt\n",
    "- extract 1-3 word phrases that are semantically important to the sentence (with confidence scores)\n",
    "'''\n",
    "\n",
    "# ── YAKE (fallback KPE) ───────────────────────────────────────────────────────\n",
    "import yake\n",
    "_yake = yake.KeywordExtractor(lan=\"en\", n=3, dedupLim=0.7, top=10)\n",
    "print(\"YAKE ready (fallback KPE)\")\n",
    "\n",
    "'''\n",
    "yake:\n",
    "- extracts keywords using statistical patterns\n",
    "- faster than keybert, will replace it if keybert fails to find keywords\n",
    "'''\n",
    "# ── dateparser ────────────────────────────────────────────────────────────────\n",
    "import dateparser\n",
    "print(\"dateparser ready\")\n",
    "\n",
    "# ── NLTK ──────────────────────────────────────────────────────────────────────\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords as _sw\n",
    "STOPWORDS = set(_sw.words(\"english\"))\n",
    "\n",
    "print(\"\\nAll modules loaded.  IST now:\", now_ist().strftime(\"%Y-%m-%d %H:%M %Z\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 — Task Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task schema ready.\n"
     ]
    }
   ],
   "source": [
    "PRIORITY_ORDER = {\"Low\": 0, \"Medium\": 1, \"High\": 2, \"Critical\": 3}\n",
    "\n",
    "print(\"dataclass is:\", dataclass)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Task:\n",
    "    action:             str\n",
    "    assignee:           Optional[str]        = None\n",
    "    deadline:           Optional[datetime]   = None\n",
    "    priority:           str                  = \"Medium\"\n",
    "    confidence:         float                = 0.5\n",
    "    keyphrases:         List[str]            = field(default_factory=list)\n",
    "    ner_entities:       Dict[str, List[str]] = field(default_factory=dict)\n",
    "    evidence_sentence:  str                  = \"\"\n",
    "    priority_breakdown: Dict[str, float]     = field(default_factory=dict)\n",
    "\n",
    "def task_to_dict(t: Task) -> Dict[str, Any]:\n",
    "    d = asdict(t)\n",
    "    d[\"deadline\"] = iso_ist(t.deadline)\n",
    "    return d\n",
    "\n",
    "def display_task(t: Task, idx: int = 1) -> None:\n",
    "    bar = {\"Low\": \"░░\", \"Medium\": \"▒▒▒\", \"High\": \"████\", \"Critical\": \"██████ ⚠\"}.get(t.priority, \"\")\n",
    "    print(f\"  +-- Task {idx}  [{t.priority}] {bar}\")\n",
    "    print(f\"  |  Action     : {t.action}\")\n",
    "    print(f\"  |  Assignee   : {t.assignee or '(unassigned)'}\")\n",
    "    print(f\"  |  Deadline   : {iso_ist(t.deadline) or '(not specified)'}\")\n",
    "    print(f\"  |  Confidence : {t.confidence:.0%}\")\n",
    "    if t.keyphrases:\n",
    "        print(f\"  |  Keyphrases : {', '.join(t.keyphrases[:4])}\")\n",
    "    for lbl, vals in t.ner_entities.items():\n",
    "        if vals: print(f\"  |  NER {lbl:<8}: {', '.join(vals)}\")\n",
    "    ev = t.evidence_sentence\n",
    "    print(f\"  |  Evidence   : {ev[:80]}{'...' if len(ev)>80 else ''}\")\n",
    "    pb = t.priority_breakdown\n",
    "    if pb:\n",
    "        parts = \"  \".join(f\"{k}={v:.2f}\" for k,v in pb.items() if k not in (\"total\", \"rerank_reason\"))\n",
    "        print(f\"  |  Score      : total={pb.get('total',0):.3f}  ({parts})\")\n",
    "        if pb.get('rerank_reason'):\n",
    "            print(f\"  |  Rerank     : {pb['rerank_reason']}\")\n",
    "    print(f\"  +{'-'*62}\")\n",
    "\n",
    "print(\"Task schema ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 — Sentence Segmentation & Task-Sentence Detection\n",
    "\n",
    "Two-pass detection:\n",
    "- **Pass 1 (rules):** action-verb presence, imperative cues, bullet markers, NER boosts\n",
    "- **Pass 2 (KPE):** KeyBERT keyphrase confidence refines the score\n",
    "\n",
    "Final score = 0.65 × rule_score + 0.35 × kpe_score. Threshold: ≥ 0.35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 3/6 task sentences:\n",
      "  rule=0.95 kpe=0.77 final=0.89  -> 'Please submit the Q1 report by Friday EOD.'\n",
      "  rule=0.70 kpe=0.70 final=0.70  -> 'Alice needs to review the design docs by Wednesday 3pm.'\n",
      "  rule=0.70 kpe=0.67 final=0.69  -> 'Escalate INC-55421 to L3 support immediately — this is a blocker.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nACTION VERB\\t0.30\\tHighest — Core signal a sentence is a task\\nCUES\\t0.20\\tMedium — Confirms it\\'s a REQUEST (not just describing an action)\\nBULLET POINT\\t0.20\\tMedium — Lists format = structured tasks\\nREQUEST FRAME\\t0.15\\tSofter — \"please/can you\" is polite but less strong\\nPERSON entity\\t0.10\\tWeakest — Just presence of a name (could be context)\\nDATE entity\\t0.10\\tWeakest — Just presence of a date\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTION_VERBS = {\n",
    "    \"send\",\"share\",\"prepare\",\"review\",\"approve\",\"confirm\",\"schedule\",\"arrange\",\n",
    "    \"deploy\",\"rollback\",\"investigate\",\"fix\",\"resolve\",\"draft\",\"update\",\"revert\",\n",
    "    \"purchase\",\"raise\",\"escalate\",\"complete\",\"submit\",\"fill\",\"sign\",\"onboard\",\n",
    "    \"provision\",\"reset\",\"enable\",\"disable\",\"patch\",\"restart\",\"monitor\",\"validate\",\n",
    "    \"verify\",\"audit\",\"reconcile\",\"process\",\"report\",\"summarize\",\"circulate\",\n",
    "    \"collect\",\"finalize\",\"coordinate\",\"notify\",\"inform\",\"upload\",\"migrate\",\"block\",\n",
    "    \"rotate\",\"renew\",\"close\",\"amend\",\"check\",\"test\",\"merge\",\"archive\",\"backup\",\n",
    "    \"restore\",\"respond\",\"follow\",\"ensure\",\"create\",\"build\",\"implement\",\"execute\",\n",
    "    \"initiate\",\"track\",\"document\",\"shortlist\",\"onboard\",\"recruit\",\"deploy\",\n",
    "}\n",
    "\n",
    "IMPERATIVE_CUES = [\n",
    "    \"please\",\"kindly\",\"must\",\"should\",\"need to\",\"needs to\",\"required\",\n",
    "    \"urgent\",\"asap\",\"immediately\",\"action required\",\"can you\",\"could you\",\n",
    "    \"would you\",\"ensure\",\"make sure\",\"follow up\",\"high priority\",\"blocker\",\n",
    "    \"by eod\",\"by cob\",\"by friday\",\"by monday\",\"by tomorrow\",\"by today\",\n",
    "    \"deadline\",\"no later than\",\"due by\",\n",
    "]\n",
    "\n",
    "NON_TASK = [\n",
    "    r\"^(hi|hello|dear|hey|good morning|good afternoon)\\b\",\n",
    "    r\"\\b(fyi|for your information|just to let you know|heads up)\\b\",\n",
    "    r\"^(thanks|thank you|regards|best regards)[.,! ]*$\",\n",
    "]\n",
    "\n",
    "def segment_sentences(text: str) -> List[str]:\n",
    "    lines = text.strip().splitlines()\n",
    "    out = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if re.match(r'^[-*•]\\s+', line) or re.match(r'^\\d+[.)\\s]', line):\n",
    "            out.append(line)  # bullet lines: preserve as-is\n",
    "        else:\n",
    "            out.extend(sent_tokenize(line))\n",
    "    seen, result = set(), []\n",
    "    for s in out:\n",
    "        key = s.lower().strip()\n",
    "        if key not in seen and len(s.split()) >= 3:\n",
    "            seen.add(key); result.append(s)\n",
    "    return result\n",
    "\n",
    "def _rule_score(sent: str) -> Tuple[bool, float]:\n",
    "    low = sent.lower().strip()\n",
    "    for pat in NON_TASK:\n",
    "        if re.search(pat, low): return False, 0.0\n",
    "    if len(sent.split()) < 4: return False, 0.0\n",
    "\n",
    "    score = 0.0\n",
    "    verb_hits = [v for v in ACTION_VERBS if re.search(r'\\b' + v + r'\\b', low)]\n",
    "    cue_hits  = [c for c in IMPERATIVE_CUES if c in low]\n",
    "    score += 0.30 * min(len(verb_hits), 2)\n",
    "    score += 0.20 * min(len(cue_hits),  3)\n",
    "    if re.match(r'^[-*•]\\s+', sent) or re.match(r'^\\d+[.)\\s]', sent):\n",
    "        score += 0.20  # bullet = very likely a task\n",
    "    if re.match(r'(please|kindly|can you|could you|would you)\\b', low, re.I):\n",
    "        score += 0.15  # request frame\n",
    "    # NER boost: person or date in sentence suggests actionable\n",
    "    doc = nlp(sent)\n",
    "    if any(e.label_ in ('PERSON','ORG') for e in doc.ents): score += 0.10\n",
    "    if any(e.label_ in ('DATE','TIME') for e in doc.ents):  score += 0.10\n",
    "\n",
    "    is_cand = bool(verb_hits or cue_hits) and score >= 0.25\n",
    "    return is_cand, min(0.95, score)\n",
    "\n",
    "def kpe_confidence(sent: str) -> Tuple[float, List[str]]:\n",
    "    \"\"\"KeyBERT primary, YAKE fallback.\"\"\"\n",
    "    try:\n",
    "        kps = kw_model.extract_keywords(\n",
    "            sent, keyphrase_ngram_range=(1,3), stop_words='english',\n",
    "            use_mmr=True, diversity=0.5, top_n=5)\n",
    "        if kps:\n",
    "            return float(kps[0][1]), [k for k,_ in kps]\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        yks = _yake.extract_keywords(sent)\n",
    "        if yks:\n",
    "            return max(0.0, 1.0 - float(yks[0][1])), [k for k,_ in yks[:5]]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return 0.0, []\n",
    "\n",
    "def detect_task_sentences(sentences: List[str], threshold: float = 0.35) -> List[Dict]:\n",
    "    results = []\n",
    "    for sent in sentences:\n",
    "        is_cand, rule_s = _rule_score(sent)\n",
    "        if not is_cand: continue\n",
    "        kpe_s, kps = kpe_confidence(sent)\n",
    "        final = 0.65 * rule_s + 0.35 * kpe_s\n",
    "        if final >= threshold:\n",
    "            results.append({\"sentence\": sent, \"rule_score\": round(rule_s,3),\n",
    "                            \"kpe_score\": round(kpe_s,3), \"final_score\": round(final,3),\n",
    "                            \"keyphrases\": kps})\n",
    "    return results\n",
    "\n",
    "# smoke test\n",
    "_test_sents = [\n",
    "    \"Hi team, thanks for joining today.\",\n",
    "    \"Please submit the Q1 report by Friday EOD.\",\n",
    "    \"Alice needs to review the design docs by Wednesday 3pm.\",\n",
    "    \"The meeting was productive.\",\n",
    "    \"Escalate INC-55421 to L3 support immediately — this is a blocker.\",\n",
    "    \"FYI: server will be down for maintenance tonight.\",\n",
    "]\n",
    "_det = detect_task_sentences(_test_sents)\n",
    "print(f\"Detected {len(_det)}/{len(_test_sents)} task sentences:\")\n",
    "for d in _det:\n",
    "    print(f\"  rule={d['rule_score']:.2f} kpe={d['kpe_score']:.2f} final={d['final_score']:.2f}  -> '{d['sentence'][:65]}'\")\n",
    "\n",
    "'''\n",
    "ACTION VERB\t0.30\tHighest — Core signal a sentence is a task\n",
    "CUES\t0.20\tMedium — Confirms it's a REQUEST (not just describing an action)\n",
    "BULLET POINT\t0.20\tMedium — Lists format = structured tasks\n",
    "REQUEST FRAME\t0.15\tSofter — \"please/can you\" is polite but less strong\n",
    "PERSON entity\t0.10\tWeakest — Just presence of a name (could be context)\n",
    "DATE entity\t0.10\tWeakest — Just presence of a date\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5 — Named Entity Recognition (spaCy)\n",
    "\n",
    "Extracts entities from each task sentence:\n",
    "- **PERSON / ORG** → assignee candidates\n",
    "- **DATE / TIME** → deadline candidates  \n",
    "- **TICKET** (regex) → INC-xxxxx, SEV-x, JIRA-xxxxx\n",
    "- **EMAIL** (regex) → email addresses\n",
    "\n",
    "Assignee is resolved through a **7-level priority sieve** (most specific first).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER + Assignee sieve demo (with recipient-verb guard):\n",
      "\n",
      "  OK  Assignee='Alice'       'Alice, please finalize the API integration by Wednesday.'\n",
      "  OK  Assignee='Bob'         'Bob should deploy release v2.4.1 to staging by 7pm today.'\n",
      "  OK  Assignee='SRE'         'Can you escalate INC-55421 to the SRE team immediately?'\n",
      "  OK  Assignee='Finance'     'Send the invoice to finance@corp.com by EOD Friday.'\n",
      "  OK  Assignee='Rahul'       'Rahul to share revised timeline by tomorrow 5pm.'\n",
      "  OK  Assignee=None          'If you are unable to attend, please inform HR by March 12th.'\n",
      "  OK  Assignee=None          'Please notify the client about the delay by tomorrow.'\n",
      "\n",
      "All assignee tests passed.\n"
     ]
    }
   ],
   "source": [
    "EMAIL_RE  = re.compile(r'\\b[A-Za-z0-9._%+\\-]+@[A-Za-z0-9.\\-]+\\.[A-Za-z]{2,}\\b')\n",
    "TICKET_RE = re.compile(r'\\b(?:INC|SEV|JIRA|TKT|SR|CRM)[\\-\\s]?\\d{3,8}\\b', re.I)\n",
    "RELEVANT_LABELS = {'PERSON','ORG','DATE','TIME','GPE','EVENT','MONEY','CARDINAL'}\n",
    "\n",
    "# Verbs where the following ORG/PERSON is a *recipient*, not the assignee\n",
    "RECIPIENT_VERBS = {'inform','notify','contact','email','cc','copy','send','forward',\n",
    "                   'alert','update','tell','report','escalate','remind'}\n",
    "\n",
    "def run_ner(sentence: str) -> Dict[str, List[str]]:\n",
    "    doc = nlp(sentence)\n",
    "    entities: Dict[str, List[str]] = defaultdict(list)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ not in RELEVANT_LABELS: continue\n",
    "        text = ent.text.strip()\n",
    "        if len(text) < 2 or text.lower() in STOPWORDS: continue\n",
    "        if text.lower() not in [x.lower() for x in entities[ent.label_]]:\n",
    "            entities[ent.label_].append(text)\n",
    "    for m in EMAIL_RE.finditer(sentence):\n",
    "        t = m.group(0)\n",
    "        if t not in entities['EMAIL']: entities['EMAIL'].append(t)\n",
    "    for m in TICKET_RE.finditer(sentence):\n",
    "        t = m.group(0).upper()\n",
    "        if t not in entities['TICKET']: entities['TICKET'].append(t)\n",
    "    return dict(entities)\n",
    "\n",
    "def _is_recipient_entity(entity_text: str, sentence: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if entity_text appears as a direct object of a recipient verb\n",
    "    (meaning it is the TARGET, not the ACTOR).\n",
    "    e.g. 'please inform HR' → HR is recipient.\n",
    "    \"\"\"\n",
    "    low = sentence.lower()\n",
    "    et  = entity_text.lower()\n",
    "    for verb in RECIPIENT_VERBS:\n",
    "        # pattern: verb ... entity_text  (within 6 words)\n",
    "        pattern = rf'\\b{verb}\\b[^.{{0,40}}?]{{0,40}}?\\b{re.escape(et)}\\b'\n",
    "        if re.search(pattern, low):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def pick_assignee(ner: Dict[str, List[str]], sentence: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    7-level sieve (first match wins):\n",
    "      1. Vocative:   'Alice, please ...'\n",
    "      2. Bullet:     'Rahul to <verb>'\n",
    "      3. Explicit:   'assign to / for <name>'\n",
    "      4. spaCy PERSON (skip if recipient of inform/notify/contact)\n",
    "      5. EMAIL local-part\n",
    "      6. ORG  (skip if recipient of inform/notify/contact/send)\n",
    "      7. None\n",
    "    \"\"\"\n",
    "    s = re.sub(r'^[-*•\\d.]+\\s*', '', sentence).strip()\n",
    "\n",
    "    # 1. Vocative: starts with 'Name,'\n",
    "    m = re.match(r'^([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)\\s*,', s)\n",
    "    if m: return m.group(1)\n",
    "\n",
    "    # 2. Bullet '<Name> to <verb>'\n",
    "    m = re.match(r'^([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)\\s+to\\s+', s)\n",
    "    if m: return m.group(1)\n",
    "\n",
    "    # 3. Explicit assign phrase\n",
    "    m = re.search(r'\\b(?:assign(?:ed)?\\s+to|for)\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+){0,2})\\b', s)\n",
    "    if m: return m.group(1)\n",
    "\n",
    "    # 4. spaCy PERSON — skip if they are a recipient of a reporting/contact verb\n",
    "    for person in ner.get('PERSON', []):\n",
    "        if not _is_recipient_entity(person, sentence):\n",
    "            return person\n",
    "\n",
    "    # 5. Email local-part\n",
    "    if ner.get('EMAIL'):\n",
    "        return ner['EMAIL'][0].split('@')[0].replace('.', ' ').replace('_', ' ').title()\n",
    "\n",
    "    # 5.5. Collective / implicit actor (participants, 'your', 'if you', etc.)\n",
    "    collective = _pick_collective_assignee(sentence)\n",
    "    if collective: return collective\n",
    "\n",
    "    # 6. ORG — skip if recipient\n",
    "    for org in ner.get('ORG', []):\n",
    "        if not _is_recipient_entity(org, sentence):\n",
    "            return org\n",
    "\n",
    "    return None\n",
    "\n",
    "# Collective / audience nouns that map to an implicit actor label\n",
    "COLLECTIVE_ACTORS = {\n",
    "    'participants':       'Participants',\n",
    "    'attendees':          'Participants',\n",
    "    'all team members':   'All team members',\n",
    "    'all staff':          'All staff',\n",
    "    'team members':       'Team members',\n",
    "    'department heads':   'Department heads',\n",
    "    'departments':        'Departments',\n",
    "    'everyone':           'All participants',\n",
    "    'all employees':      'All employees',\n",
    "    'all users':          'All users',\n",
    "}\n",
    "\n",
    "def _pick_collective_assignee(sentence: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Detect collective or implicit actors that spaCy PERSON NER misses:\n",
    "      - Explicit collective nouns: 'Participants', 'Department heads', etc.\n",
    "      - Possessive 'your' implies the addressed audience → 'Participants'\n",
    "      - Conditional 'if you / you are' → 'Participants'\n",
    "    Returns None when no collective actor is found.\n",
    "    \"\"\"\n",
    "    low = sentence.lower()\n",
    "    for phrase, label in COLLECTIVE_ACTORS.items():\n",
    "        if re.search(r'\\b' + re.escape(phrase) + r'\\b', low):\n",
    "            return label\n",
    "    # 'your' in sentence implies addressed audience\n",
    "    if re.search(r'\\byour\\b', low):\n",
    "        return 'Participants'\n",
    "    # conditional / imperative 'you'\n",
    "    if re.search(r'\\bif you\\b|\\byou are\\b|\\byou must\\b|\\byou should\\b', low):\n",
    "        return 'Participants'\n",
    "    return None\n",
    "\n",
    "# ── Demo ──────────────────────────────────────────────────────────────────────\n",
    "_ner_demos = [\n",
    "    (\"Alice, please finalize the API integration by Wednesday.\",                    \"Alice\"),\n",
    "    (\"Bob should deploy release v2.4.1 to staging by 7pm today.\",                  \"Bob\"),\n",
    "    (\"Can you escalate INC-55421 to the SRE team immediately?\",                    \"SRE\"),\n",
    "    (\"Send the invoice to finance@corp.com by EOD Friday.\",                        \"Finance\"),\n",
    "    (\"Rahul to share revised timeline by tomorrow 5pm.\",                           \"Rahul\"),\n",
    "    (\"If you are unable to attend, please inform HR by March 12th.\",               \"Participants\"),\n",
    "    (\"Please notify the client about the delay by tomorrow.\",                      None),\n",
    "    (\"Participants are requested to report by 9:00 AM on March 18th.\",             \"Participants\"),\n",
    "    (\"Kindly submit your department presentations by March 10th.\",                  \"Participants\"),\n",
    "]\n",
    "print(\"NER + Assignee sieve demo (with recipient-verb guard):\\n\")\n",
    "all_ok = True\n",
    "for ex, expected in _ner_demos:\n",
    "    ner = run_ner(ex)\n",
    "    a   = pick_assignee(ner, ex)\n",
    "    ok  = (a == expected) or (a is None and expected is None)\n",
    "    if not ok: all_ok = False\n",
    "    mark = \"OK\" if ok else \"FAIL\"\n",
    "    print(f\"  {mark}  Assignee={a!r:<12}  '{ex}'\")\n",
    "print()\n",
    "print(\"All assignee tests passed.\" if all_ok else \"Some assignee tests FAILED.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6 — Deadline Extraction & Normalization\n",
    "\n",
    "**Stage 1:** Regex bank (10 patterns, ordered most-specific first) extracts raw phrases.\n",
    "\n",
    "**Stage 2:** Normalizer maps each phrase to an IST `datetime`:\n",
    "ISO → compound (tomorrow+EOD) → within-X → EOD/COB → relative → weekday → time → dateparser fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deadline tests (anchor 2026-02-15 10:00 IST):\n",
      "\n",
      "  OK  'Submit by EOD today.                         ' -> 2026-02-15T18:00:00+05:30  ('by EOD today')\n",
      "  OK  'Send by tomorrow 3pm.                        ' -> 2026-02-16T15:00:00+05:30  ('by tomorrow 3pm')\n",
      "  OK  'Complete within 4 hours.                     ' -> 2026-02-15T14:00:00+05:30  ('within 4 hours')\n",
      "  OK  'Due by next Friday.                          ' -> 2026-02-20T17:00:00+05:30  ('Due by next Friday')\n",
      "  OK  'Deadline: 2026-02-20.                        ' -> 2026-02-20T17:00:00+05:30  ('2026-02-20')\n",
      "  OK  'Resolve by Friday 12pm.                      ' -> 2026-02-20T12:00:00+05:30  ('by Friday 12pm')\n",
      "  OK  'Fix the issue by Monday COB.                 ' -> 2026-02-16T17:00:00+05:30  ('by Monday COB')\n",
      "  OK  'Complete before March 15th.                  ' -> 2026-03-15T17:00:00+05:30  ('before March 15th')\n",
      "\n",
      "All tests passed.\n"
     ]
    }
   ],
   "source": [
    "import calendar as _cal\n",
    "\n",
    "DOW = {\"monday\":0,\"tuesday\":1,\"wednesday\":2,\"thursday\":3,\"friday\":4,\"saturday\":5,\"sunday\":6}\n",
    "MONTHS = {m.lower():i for i,m in enumerate(_cal.month_name) if m}\n",
    "MONTHS.update({m.lower():i for i,m in enumerate(_cal.month_abbr) if m})\n",
    "\n",
    "DEADLINE_PATTERNS = [\n",
    "    # ISO datetime (most specific)\n",
    "    r'\\b20\\d{2}-\\d{2}-\\d{2}(?:[T\\s]\\d{2}:\\d{2}(?::\\d{2})?)?\\b',\n",
    "    # named month + day + optional year + optional time  (e.g. \"March 18th\", \"Feb 28, 2026 5pm\")\n",
    "    r'\\b(?:jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|'\n",
    "    r'jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?)'\n",
    "    r'\\s+\\d{1,2}(?:st|nd|rd|th)?(?:,?\\s*\\d{4})?(?:\\s+\\d{1,2}(?::\\d{2})?\\s*(?:am|pm)?)?\\b',\n",
    "    # compound relative: tomorrow/today + EOD/COB/time\n",
    "    r'\\b(tomorrow|today)\\s+(eod|cob|end of day|close of business|\\d{1,2}(?::\\d{2})?\\s*(?:am|pm)?)\\b',\n",
    "    # within X hours/days\n",
    "    r'\\bwithin\\s+\\d+\\s*(hours?|days?)\\b',\n",
    "    # by/before/due + clause (catches \"by Friday COB\", \"before next Monday 5pm\")\n",
    "    r'\\b(?:by|before|due|no later than)\\s+[^,.;\\n]{1,55}',\n",
    "    # standalone EOD/COB (today only — listed AFTER the compound & by-clause patterns)\n",
    "    r'\\b(eod|cob|end of day|close of business)\\b',\n",
    "    # relative singles\n",
    "    r'\\b(today|tomorrow|day after tomorrow)\\b',\n",
    "    # next/this weekday\n",
    "    r'\\b(?:next|this)\\s+(monday|tuesday|wednesday|thursday|friday|saturday|sunday)\\b',\n",
    "    # bare weekday\n",
    "    r'\\b(monday|tuesday|wednesday|thursday|friday|saturday|sunday)\\b',\n",
    "    # in X days/hours\n",
    "    r'\\bin\\s+\\d+\\s*(days?|hours?)\\b',\n",
    "    # by <time-only>\n",
    "    r'\\bby\\s+\\d{1,2}(?::\\d{2})?\\s*(?:am|pm)?\\b',\n",
    "    # end of <period>\n",
    "    r'\\bend of (?:next )?week\\b',\n",
    "]\n",
    "\n",
    "def _set_t(dt, hh, mm=0): return ensure_ist(dt).replace(hour=hh,minute=mm,second=0,microsecond=0)\n",
    "\n",
    "def _next_dow(anchor: datetime, target: int) -> datetime:\n",
    "    diff = (target - anchor.weekday()) % 7 or 7\n",
    "    return _set_t(ensure_ist(anchor + timedelta(days=diff)), 17)\n",
    "\n",
    "def _parse_ampm(h, mi, ampm):\n",
    "    hh, mm = int(h), int(mi or 0)\n",
    "    if ampm:\n",
    "        if ampm.lower() == 'pm' and hh < 12: hh += 12\n",
    "        if ampm.lower() == 'am' and hh == 12: hh = 0\n",
    "    return hh, mm\n",
    "\n",
    "def _parse_named_month(phrase: str, anchor: datetime) -> Optional[datetime]:\n",
    "    \"\"\"\n",
    "    Parse phrases like 'March 18th', 'Feb 28, 2026 5pm', 'March 15th by 3pm'.\n",
    "    Always anchors to the correct calendar year (next occurrence if month already passed).\n",
    "    \"\"\"\n",
    "    p = phrase.strip().lower()\n",
    "    # strip leading by/before/due\n",
    "    p = re.sub(r'^(?:by|before|due|no later than)\\s+', '', p).strip()\n",
    "\n",
    "    # Use re.search (not re.match) so the month name is found anywhere in the phrase,\n",
    "    # e.g. \"by 9:00 AM on March 18th\" where the time precedes the month name.\n",
    "    mo_m = re.search(\n",
    "        r'(jan(?:uary)?|feb(?:ruary)?|mar(?:ch)?|apr(?:il)?|may|jun(?:e)?|'\n",
    "        r'jul(?:y)?|aug(?:ust)?|sep(?:tember)?|oct(?:ober)?|nov(?:ember)?|dec(?:ember)?)'\n",
    "        r'\\s+(\\d{1,2})(?:st|nd|rd|th)?(?:,?\\s*(\\d{4}))?'\n",
    "        r'(?:\\s+(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)?)?'\n",
    "        r'(?:\\s+(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)?)?'\n",
    "        r'(?:\\s+(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)?)?',\n",
    "        p, re.I\n",
    "    )\n",
    "    if not mo_m:\n",
    "        return None\n",
    "\n",
    "    mon_str, day_str = mo_m.group(1), mo_m.group(2)\n",
    "    yr_str  = mo_m.group(3)\n",
    "    h_str, mi_str, ampm_str = mo_m.group(4), mo_m.group(5), mo_m.group(6)\n",
    "\n",
    "    mon = MONTHS.get(mon_str.lower()[:3])\n",
    "    if not mon: return None\n",
    "    day = int(day_str)\n",
    "    yr  = int(yr_str) if yr_str else anchor.year\n",
    "\n",
    "    # If no year given and the month/day is already past in anchor year, use next year\n",
    "    try:\n",
    "        candidate = ensure_ist(datetime(yr, mon, day))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    if not yr_str and candidate.date() < ensure_ist(anchor).date():\n",
    "        try:\n",
    "            candidate = ensure_ist(datetime(yr + 1, mon, day))\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    if h_str:\n",
    "        hh, mm = _parse_ampm(h_str, mi_str, ampm_str)\n",
    "        return _set_t(candidate, hh, mm)\n",
    "\n",
    "    # If no time attached to the month, look for a time BEFORE the month in the phrase.\n",
    "    # Handles \"by 9:00 AM on March 18th\" where the time precedes the month name.\n",
    "    pre_month = p[:mo_m.start()]\n",
    "    pre_time  = re.search(r'(\\d{1,2}):(\\d{2})\\s*(am|pm)?', pre_month, re.I)\n",
    "    if pre_time:\n",
    "        hh, mm = _parse_ampm(pre_time.group(1), pre_time.group(2), pre_time.group(3))\n",
    "        return _set_t(candidate, hh, mm)\n",
    "\n",
    "    return _set_t(candidate, 17)   # default COB\n",
    "\n",
    "def _normalize_phrase(phrase: str, anchor: datetime) -> Optional[datetime]:\n",
    "    p, a = phrase.strip().lower(), ensure_ist(anchor)\n",
    "\n",
    "    # ISO\n",
    "    m = re.search(r'(20\\d{2}-\\d{2}-\\d{2})(?:[T\\s](\\d{2}:\\d{2}))?', p)\n",
    "    if m:\n",
    "        try: return ensure_ist(datetime.fromisoformat(m.group(1)+' '+(m.group(2) or '17:00')))\n",
    "        except Exception: pass\n",
    "\n",
    "    # Named month (e.g. \"March 18th\", \"before March 15th\", \"by Feb 28 2026 5pm\")\n",
    "    named = _parse_named_month(phrase, anchor)\n",
    "    if named: return named\n",
    "\n",
    "    # within X hours/days\n",
    "    m = re.search(r'within\\s+(\\d+)\\s*(hours?|days?)', p)\n",
    "    if m:\n",
    "        n, u = int(m.group(1)), m.group(2)\n",
    "        delta = timedelta(hours=n) if 'h' in u else timedelta(days=n)\n",
    "        base  = ensure_ist(a + delta)\n",
    "        return base.replace(second=0,microsecond=0) if 'h' in u else _set_t(base, 17)\n",
    "\n",
    "    # tomorrow\n",
    "    if 'tomorrow' in p:\n",
    "        base = a + timedelta(days=1)\n",
    "        if 'eod' in p or 'end of day' in p: return _set_t(base, 18)\n",
    "        if 'cob' in p or 'close of business' in p: return _set_t(base, 17)\n",
    "        m = re.search(r'(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)?', p)\n",
    "        if m:\n",
    "            hh, mm = _parse_ampm(m.group(1), m.group(2), m.group(3))\n",
    "            return _set_t(base, hh, mm)\n",
    "        return _set_t(base, 17)\n",
    "\n",
    "    # ── KEY FIX: check for weekday BEFORE standalone EOD/COB ─────────────────\n",
    "    # \"by Monday COB\" must be caught as weekday+cob, not just 'cob today'\n",
    "    dow_m = re.search(r'(next|this)?\\s*(monday|tuesday|wednesday|thursday|friday|saturday|sunday)', p)\n",
    "    if dow_m:\n",
    "        base = _next_dow(a, DOW[dow_m.group(2)])\n",
    "        if dow_m.group(1) == 'next' and base.date() == a.date():\n",
    "            base = base + timedelta(days=7)\n",
    "        # apply EOD/COB/time override on that weekday\n",
    "        if 'eod' in p or 'end of day' in p: return _set_t(base, 18)\n",
    "        if 'cob' in p or 'close of business' in p: return _set_t(base, 17)\n",
    "        tm = re.search(r'(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)?', p)\n",
    "        if tm:\n",
    "            hh, mm2 = _parse_ampm(tm.group(1), tm.group(2), tm.group(3))\n",
    "            return _set_t(base, hh, mm2)\n",
    "        return base\n",
    "\n",
    "    # standalone EOD / COB (today, no weekday context)\n",
    "    if 'eod' in p or 'end of day' in p: return _set_t(a, 18)\n",
    "    if 'cob' in p or 'close of business' in p: return _set_t(a, 17)\n",
    "\n",
    "    # day after tomorrow\n",
    "    if 'day after tomorrow' in p: return _set_t(a + timedelta(days=2), 17)\n",
    "\n",
    "    # today + optional time\n",
    "    if re.search(r'^today\\s*$', p): return _set_t(a, 17)\n",
    "    if 'today' in p:\n",
    "        m = re.search(r'(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)?', p)\n",
    "        if m:\n",
    "            hh, mm = _parse_ampm(m.group(1), m.group(2), m.group(3))\n",
    "            return _set_t(a, hh, mm)\n",
    "        return _set_t(a, 17)\n",
    "\n",
    "    # before <weekday>  (handled by weekday block above, but keep as safety)\n",
    "    m = re.search(r'before\\s+(monday|tuesday|wednesday|thursday|friday|saturday|sunday)', p)\n",
    "    if m: return _next_dow(a, DOW[m.group(1)]) - timedelta(days=1)\n",
    "\n",
    "    # in X days/hours\n",
    "    m = re.search(r'in\\s+(\\d+)\\s*(days?|hours?)', p)\n",
    "    if m:\n",
    "        n, u = int(m.group(1)), m.group(2)\n",
    "        base = ensure_ist(a + (timedelta(hours=n) if 'h' in u else timedelta(days=n)))\n",
    "        return base.replace(second=0,microsecond=0) if 'h' in u else _set_t(base, 17)\n",
    "\n",
    "    # end of week / end of next week\n",
    "    m = re.search(r'end of (next )?week', p)\n",
    "    if m:\n",
    "        days_to_fri = (4 - a.weekday()) % 7 or 7\n",
    "        if m.group(1): days_to_fri += 7\n",
    "        return _set_t(a + timedelta(days=days_to_fri), 17)\n",
    "\n",
    "    # by <time-only>\n",
    "    m = re.search(r'by\\s+(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)?', p)\n",
    "    if m:\n",
    "        hh, mm = _parse_ampm(m.group(1), m.group(2), m.group(3))\n",
    "        return _set_t(a, hh, mm)\n",
    "\n",
    "    # dateparser fallback — always pass anchor as RELATIVE_BASE\n",
    "    try:\n",
    "        parsed = dateparser.parse(phrase, settings={\n",
    "            'PREFER_DAY_OF_MONTH': 'first',\n",
    "            'PREFER_DATES_FROM': 'future',\n",
    "            'TIMEZONE': 'Asia/Kolkata',\n",
    "            'RETURN_AS_TIMEZONE_AWARE': True,\n",
    "            'RELATIVE_BASE': ensure_ist(anchor)})\n",
    "        if parsed: return ensure_ist(parsed)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def _specificity(x: str) -> int:\n",
    "    \"\"\"Higher = more specific = tried first.\"\"\"    \n",
    "    xl = x.lower()\n",
    "    s = 0\n",
    "    if re.search(r'20\\d{2}-\\d{2}-\\d{2}', xl): s += 5\n",
    "    # named month with year\n",
    "    if re.search(r'\\b(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)', xl) and re.search(r'\\d{4}', xl): s += 4\n",
    "    # named month without year\n",
    "    if re.search(r'\\b(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)', xl): s += 3\n",
    "    if re.search(r'\\d{1,2}:\\d{2}|\\b(am|pm)\\b', xl): s += 2\n",
    "    if re.search(r'eod|cob', xl): s += 1\n",
    "    if re.search(r'by |before |within |no later', xl): s += 1\n",
    "    return s\n",
    "\n",
    "def extract_deadline(sentence: str, anchor: datetime) -> Tuple[Optional[datetime], str]:\n",
    "    low = sentence.lower()\n",
    "    candidates = []\n",
    "    for pat in DEADLINE_PATTERNS:\n",
    "        for m in re.finditer(pat, low, re.I):\n",
    "            candidates.append(sentence[m.start():m.end()].strip())\n",
    "    for phrase in sorted(set(candidates), key=_specificity, reverse=True):\n",
    "        dt = _normalize_phrase(phrase, anchor)\n",
    "        if dt: return dt, phrase\n",
    "    return None, ''\n",
    "\n",
    "# ── Unit tests ────────────────────────────────────────────────────────────────\n",
    "_anc = ensure_ist(datetime(2026, 2, 15, 10, 0))\n",
    "_cases = [\n",
    "    ('Submit by EOD today.',            datetime(2026,2,15,18,0), 1800),\n",
    "    ('Send by tomorrow 3pm.',           datetime(2026,2,16,15,0), 1800),\n",
    "    ('Complete within 4 hours.',        datetime(2026,2,15,14,0), 1800),\n",
    "    ('Due by next Friday.',             datetime(2026,2,20,17,0), 1800),\n",
    "    ('Deadline: 2026-02-20.',           datetime(2026,2,20,17,0), 1800),\n",
    "    ('Resolve by Friday 12pm.',         datetime(2026,2,20,12,0), 1800),\n",
    "    ('Fix the issue by Monday COB.',    datetime(2026,2,16,17,0), 1800),  # was FAIL\n",
    "    ('Report by 9:00 AM on March 18th.',datetime(2026,3,18, 9,0), 1800),  # named month with pre-phrase time\n",
    "    ('Complete before March 15th.',     datetime(2026,3,15,17,0), 1800),  # before + named month\n",
    "    ('Kindly submit by March 10th.',    datetime(2026,3,10,17,0), 1800),  # by + named month\n",
    "    ('Inform HR by March 12th.',        datetime(2026,3,12,17,0), 1800),  # by + named month\n",
    "]\n",
    "print('Deadline tests (anchor 2026-02-15 10:00 IST):\\n')\n",
    "ok_all = True\n",
    "for sent, exp, tol in _cases:\n",
    "    got, phrase = extract_deadline(sent, _anc)\n",
    "    ok = got is not None and abs((got - ensure_ist(exp)).total_seconds()) <= tol\n",
    "    if not ok: ok_all = False\n",
    "    print(f\"  {'OK' if ok else 'FAIL'}  '{sent:<45}' -> {iso_ist(got)}  ('{phrase}')\")\n",
    "print('\\nAll tests passed.' if ok_all else 'Some tests FAILED.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7 — Action Span Extraction (Verb-Anchor + KPE Refinement)\n",
    "\n",
    "1. Strip request frames (`Please`, `Can you`, bullet markers)\n",
    "2. Find first action verb (lexicon + spaCy `VB`/`VBP` tag)\n",
    "3. Expand right until a boundary clause (`however`, `but`, `thanks`)\n",
    "4. **KPE overlay:** if a KeyBERT phrase covers >55% of the span tokens, prefer it (more concise)\n",
    "5. Cap at 20 words; split compound sentences into two actions when both halves have their own verb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action extraction demo:\n",
      "\n",
      "  Input    : Please send the Q1 report to finance by Friday EOD.\n",
      "  Action   : 'q1 report finance'\n",
      "  Expected : 'send the Q1 report to finance'  MISMATCH\n",
      "\n",
      "  Input    : - Review the draft, update comments, and share the final version.\n",
      "  Action   : 'Review the draft, update comments'\n",
      "  Action   : 'share the final version'\n",
      "\n",
      "  Input    : Can you investigate the CPU spike and share RCA by tomorrow EOD?\n",
      "  Action   : 'investigate the CPU spike'\n",
      "  Action   : 'share RCA'\n",
      "\n",
      "  Input    : Alice, please deploy release v2.4.1 to staging today 7pm and share sanity results.\n",
      "  Action   : 'deploy release v2.4.1 to staging today 7pm'\n",
      "  Action   : 'share sanity results'\n",
      "\n",
      "  Input    : Rahul to share revised timeline by tomorrow 5pm.\n",
      "  Action   : 'share revised timeline'\n",
      "  Expected : 'share revised timeline'  OK\n",
      "\n",
      "  Input    : Any revisions must be completed before March 15th.\n",
      "  Action   : 'revisions completed march 15th'\n",
      "  Expected : 'revisions completed'  OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "REQUEST_FRAMES = [\n",
    "    r'^[-*•]\\s*', r'^\\d+[.)]\\s*',\n",
    "    r'^(please|kindly)\\s+',\n",
    "    r'^(can you|could you|would you)\\s+',\n",
    "    r'^(i need you to|we need to|we should|you should)\\s+',\n",
    "    r'^(action|note|summary):\\s*',\n",
    "]\n",
    "BOUNDARIES = [\n",
    "    r'\\b(thanks|regards|fyi|please note|as discussed|note that)\\b',\n",
    "    r'\\s+(?:however|but|although|though)\\s+',\n",
    "    r'\\s+and then\\s+',\n",
    "]\n",
    "\n",
    "# Deadline tail patterns — stripped from the end of the action span\n",
    "DEADLINE_TAILS = [\n",
    "    r'\\s+by\\s+\\S+.*$',              # \"by Friday EOD\", \"by tomorrow 5pm\"\n",
    "    r'\\s+before\\s+\\S+.*$',          # \"before next Monday\"\n",
    "    r'\\s+no later than\\s+.*$',\n",
    "    r'\\s+(?:eod|cob|end of day).*$',\n",
    "    r'\\s+within\\s+\\d+\\s*(?:hours?|days?).*$',\n",
    "    r'[.!?]+$',                        # trailing punctuation\n",
    "]\n",
    "\n",
    "def _strip_frame(s: str) -> str:\n",
    "    \"\"\"Strip leading request prefixes and bullet markers.\"\"\"    \n",
    "    for pat in REQUEST_FRAMES:\n",
    "        s = re.sub(pat, '', s, flags=re.I).strip()\n",
    "    return s\n",
    "\n",
    "def _strip_deadline_tail(span: str) -> str:\n",
    "    \"\"\"Remove trailing deadline/temporal clause from the action span.\"\"\"    \n",
    "    original = span\n",
    "    for pat in DEADLINE_TAILS:\n",
    "        span = re.sub(pat, '', span, flags=re.I).strip()\n",
    "    span = span.strip(' ,;:-.!?')\n",
    "    # Guard: only revert if stripping produced a single word or empty string.\n",
    "    # Two-word actions like \"inform HR\" or \"complete revisions\" are valid and kept.\n",
    "    if len(span.split()) < 2:\n",
    "        span = re.sub(r'[.!?]+$', '', original).strip(' ,;:-.!?')\n",
    "    return span\n",
    "\n",
    "# Common VBN (past participle) → base-verb mapping for modal+passive sentences\n",
    "_VBN_TO_BASE = {\n",
    "    'completed':'complete', 'submitted':'submit',   'reviewed':'review',\n",
    "    'approved':'approve',   'finalized':'finalize', 'confirmed':'confirm',\n",
    "    'updated':'update',     'prepared':'prepare',   'processed':'process',\n",
    "    'shared':'share',       'sent':'send',           'filled':'fill',\n",
    "    'signed':'sign',        'done':'do',             'installed':'install',\n",
    "    'deployed':'deploy',    'resolved':'resolve',   'fixed':'fix',\n",
    "    'scheduled':'schedule', 'collected':'collect',  'circulated':'circulate',\n",
    "    'provided':'provide',   'uploaded':'upload',    'archived':'archive',\n",
    "}\n",
    "\n",
    "def _modal_passive_action(sentence: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Detect modal+passive constructions like \"must be completed\", \"should be submitted\".\n",
    "    Returns a normalised imperative action string, e.g. \"complete revisions\", or None.\n",
    "    \"\"\"\n",
    "    m = re.search(\n",
    "        r'\\b(?:must|should|need to|needs to|has to|have to|is to|are to|required to)'\n",
    "        r'\\s+(?:be\\s+)?([a-z]+(?:ed|en|d))\\b',\n",
    "        sentence.lower()\n",
    "    )\n",
    "    if not m:\n",
    "        return None\n",
    "    vbn  = m.group(1)\n",
    "    base = _VBN_TO_BASE.get(vbn, re.sub(r'(ed|d)$', '', vbn) if vbn.endswith('ed') else vbn)\n",
    "    # Build subject: words before the modal verb (strip articles/determiners)\n",
    "    pre = sentence[:m.start()].strip()\n",
    "    pre = re.sub(r'\\b(any|all|the|a|an)\\s+', '', pre, flags=re.I).strip()\n",
    "    if pre:\n",
    "        return f'{base} {pre.lower()}'\n",
    "    return base\n",
    "\n",
    "def _find_verb_start(doc, verbs: set) -> int:\n",
    "    \"\"\"Return char offset of first action verb in spaCy doc.\"\"\"    \n",
    "    for tok in doc:\n",
    "        if tok.tag_ in ('VB','VBP') and tok.lemma_.lower() in verbs: return tok.idx\n",
    "    for tok in doc:\n",
    "        if tok.pos_ == 'VERB' and tok.lemma_.lower() in verbs: return tok.idx\n",
    "    return 0\n",
    "\n",
    "def _cut_boundary(span: str) -> str:\n",
    "    \"\"\"Cut at discourse boundaries (however/but/thanks).\"\"\"    \n",
    "    for pat in BOUNDARIES:\n",
    "        m = re.search(pat, span, re.I)\n",
    "        if m and m.start() > 8:\n",
    "            span = span[:m.start()].strip(' ,;:-')\n",
    "    return span\n",
    "\n",
    "def _kpe_overlay(span: str, keyphrases: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Replace the verb-anchored span with a KPE keyphrase only when:\n",
    "      - keyphrase covers > 70% of span content tokens  (raised from 55%)\n",
    "      - keyphrase is at least 3 words (avoids 2-word noun replacements like 'cpu spike')\n",
    "    This keeps the keyphrase as a refinement, not a clobber.\n",
    "    \"\"\"\n",
    "    if not keyphrases: return span\n",
    "    span_toks = set(span.lower().split()) - STOPWORDS\n",
    "    for kp in keyphrases[:2]:\n",
    "        kp_toks = set(kp.lower().split()) - STOPWORDS\n",
    "        if len(kp.split()) < 3: continue          # must be at least 3 words\n",
    "        if not kp_toks: continue\n",
    "        overlap = len(span_toks & kp_toks)\n",
    "        if overlap / max(1, len(span_toks)) <= 0.70:\n",
    "            continue\n",
    "        # Reject if the KPE phrase introduces words that are not in the original span.\n",
    "        # This prevents keyphrases like \"workshop inform hr\" from injecting \"workshop\"\n",
    "        # into an action span that only contains \"inform HR\".\n",
    "        span_words = set(span.lower().split())\n",
    "        injected   = set(kp.lower().split()) - span_words - STOPWORDS\n",
    "        if injected:\n",
    "            continue\n",
    "        return kp.strip()\n",
    "    return span\n",
    "\n",
    "def extract_action(sentence: str, keyphrases: List[str]) -> str:\n",
    "    # Check for modal+passive first (\"must be completed\", \"should be submitted\").\n",
    "    # This handles imperatives expressed in passive voice before the verb-anchor path,\n",
    "    # which would otherwise latch onto a non-action word at position 0.\n",
    "    mp = _modal_passive_action(sentence)\n",
    "    if mp:\n",
    "        return mp.strip()\n",
    "    s    = _strip_frame(sentence)\n",
    "    doc  = nlp(s)\n",
    "    span = s[_find_verb_start(doc, ACTION_VERBS):].strip()\n",
    "    span = _cut_boundary(span)\n",
    "    span = _strip_deadline_tail(span)    # ← remove \"by Friday EOD\" etc.\n",
    "    words = span.split()\n",
    "    if len(words) > 20:\n",
    "        span = ' '.join(words[:20]).rstrip(' ,;:-') + '...'\n",
    "    return _kpe_overlay(span, keyphrases).strip()\n",
    "\n",
    "def split_multi_actions(sentence: str, keyphrases: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split compound task sentence into individual actions when both halves\n",
    "    independently contain an action verb and enough content tokens.\n",
    "    Only splits on ' and ', never on commas alone.\n",
    "    \"\"\"\n",
    "    if ' and ' not in sentence.lower():\n",
    "        return [extract_action(sentence, keyphrases)]\n",
    "    parts = re.split(r'\\s+and\\s+', sentence, maxsplit=1, flags=re.I)\n",
    "    if len(parts) < 2:\n",
    "        return [extract_action(sentence, keyphrases)]\n",
    "    actions = []\n",
    "    for part in parts:\n",
    "        doc = nlp(_strip_frame(part))\n",
    "        has_verb = any(t.tag_ in ('VB','VBP') and t.lemma_.lower() in ACTION_VERBS for t in doc)\n",
    "        content  = [t for t in part.split() if t.lower() not in STOPWORDS]\n",
    "        if has_verb and len(content) >= 3:\n",
    "            actions.append(extract_action(part, keyphrases))\n",
    "    return actions if len(actions) >= 2 else [extract_action(sentence, keyphrases)]\n",
    "\n",
    "# ── Demo ──────────────────────────────────────────────────────────────────────\n",
    "_action_demos = [\n",
    "    ('Please send the Q1 report to finance by Friday EOD.',\n",
    "     ['q1 report finance', 'send report'],\n",
    "     'send the Q1 report to finance'),        # deadline tail stripped\n",
    "    ('- Review the draft, update comments, and share the final version.',\n",
    "     ['review draft', 'update comments', 'final version'],\n",
    "     None),                                   # multi-split expected\n",
    "    ('Can you investigate the CPU spike and share RCA by tomorrow EOD?',\n",
    "     ['cpu spike', 'investigate rca'],\n",
    "     None),                                   # multi-split; 'cpu spike' should NOT replace\n",
    "    ('Alice, please deploy release v2.4.1 to staging today 7pm and share sanity results.',\n",
    "     ['deploy release staging', 'sanity results'],\n",
    "     None),\n",
    "    ('Rahul to share revised timeline by tomorrow 5pm.',\n",
    "     ['revised timeline', 'share timeline'],\n",
    "     'share revised timeline'),               # deadline tail stripped\n",
    "    ('Any revisions must be completed before March 15th.',\n",
    "     ['revisions completed march 15th'],\n",
    "     'complete revisions'),                   # modal+passive → imperative form\n",
    "    ('If you are unable to attend the workshop, please inform HR by March 12th.',\n",
    "     ['workshop inform hr', 'attend workshop', 'inform hr march'],\n",
    "     'inform HR'),                             # KPE injection guard: 'workshop' blocked\n",
    "]\n",
    "print('Action extraction demo:\\n')\n",
    "for item in _action_demos:\n",
    "    sent, kps, expected = item\n",
    "    actions = split_multi_actions(sent, kps)\n",
    "    ok = True\n",
    "    if expected is not None:\n",
    "        ok = (len(actions) == 1 and expected.lower() in actions[0].lower())\n",
    "    print(f\"  Input    : {sent}\")\n",
    "    for a in actions:\n",
    "        print(f\"  Action   : '{a}'\")\n",
    "    if expected is not None:\n",
    "        print(f\"  Expected : '{expected}'  {'OK' if ok else 'MISMATCH'}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8 — Priority Scoring (Weighted Multi-Factor Formula)\n",
    "\n",
    "```\n",
    "score = 0.35 × deadline_proximity\n",
    "      + 0.20 × urgency_lexicon\n",
    "      + 0.20 × risk_lexicon\n",
    "      + 0.15 × customer_impact\n",
    "      + 0.10 × authority_cues\n",
    "```\n",
    "\n",
    "Each component ∈ [0,1]. Multiple keyword hits stack (capped at 1.0).\n",
    "\n",
    "| Thresholds | Label |\n",
    "|---|---|\n",
    "| ≥ 0.75 | Critical |\n",
    "| ≥ 0.55 | High |\n",
    "| ≥ 0.30 | Medium |\n",
    "| < 0.30 | Low |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidence                                                Exp        Got         Score  Components\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "  OK  Please send the invoice to finance by EOD today.   High       High        0.280  deadline=0.80 urgency=0.00 risk=0.00 customer=0.00 authority=0.00\n",
      "  OK  Urgent: finalize the month-end accruals by tomorro Critical   Critical    0.304  deadline=0.55 urgency=0.35 risk=0.00 customer=0.00 authority=0.30\n",
      "  OK  SEV1: rollback the last deployment immediately and Critical   Critical    0.305  deadline=0.00 urgency=0.90 risk=0.40 customer=0.00 authority=0.00\n",
      "  OK  Investigate possible credential breach and share f Critical   Critical    0.420  deadline=0.80 urgency=0.00 risk=0.70 customer=0.00 authority=0.00\n",
      "  OK  Please update the internal wiki with deployment no Low        Low         0.000  deadline=0.00 urgency=0.00 risk=0.00 customer=0.00 authority=0.00\n",
      "  OK  Collect 3 quotations and finalize the rate contrac Medium     Medium      0.129  deadline=0.30 urgency=0.00 risk=0.00 customer=0.20 authority=0.00\n",
      "  OK  Urgent: apply the critical security patch on prod- Critical   Critical    0.505  deadline=0.80 urgency=0.70 risk=0.25 customer=0.00 authority=0.00\n",
      "  OK  Upload audit evidence for Q4 controls by next Frid High       High        0.225  deadline=0.30 urgency=0.00 risk=0.60 customer=0.00 authority=0.00\n",
      "  OK  Complete threat model review for the new feature b High       High        0.271  deadline=0.30 urgency=0.35 risk=0.25 customer=0.00 authority=0.35\n",
      "  OK  Rotate production database credentials immediately Critical   Critical    0.300  deadline=0.00 urgency=0.40 risk=1.00 customer=0.00 authority=0.00\n",
      "\n",
      "All priority tests passed.\n"
     ]
    }
   ],
   "source": [
    "# ─── Lexicons ────────────────────────────────────────────────────────────────\n",
    "URGENCY_LEX = {\n",
    "    # Explicit urgency only — generic time words removed to avoid false signals\n",
    "    'asap':0.40, 'urgent':0.35, 'immediately':0.40, 'right now':0.35,\n",
    "    'high priority':0.25, 'top priority':0.35, 'critical':0.35,\n",
    "    'blocker':0.35, 'escalate':0.25, 'sev1':0.50, 'sev2':0.35, 'sev3':0.20,\n",
    "    'no later than':0.20, 'action required':0.30, 'overdue':0.35,\n",
    "}\n",
    "RISK_LEX = {\n",
    "    'security':0.25, 'breach':0.45, 'incident':0.30, 'outage':0.40,\n",
    "    'compliance':0.20, 'audit':0.20, 'legal':0.20, 'penalty':0.25,\n",
    "    'data loss':0.45, 'vulnerability':0.35, 'exploit':0.40,\n",
    "    'attack':0.35, 'ransomware':0.50, 'gdpr':0.25, 'regulatory':0.20,\n",
    "    'downtime':0.30, 'failure':0.30, 'corruption':0.35,\n",
    "}\n",
    "CUSTOMER_LEX = {\n",
    "    'client':0.25, 'customer':0.25, 'sla':0.35, 'go-live':0.30,\n",
    "    'billing':0.25, 'escalation':0.25, 'churn':0.30, 'nps':0.25,\n",
    "    'contract':0.20, 'delivery':0.20,\n",
    "}\n",
    "AUTHORITY_LEX = {\n",
    "    'cfo':0.30, 'ceo':0.35, 'cto':0.35, 'coo':0.30, 'vp':0.25,\n",
    "    'director':0.25, 'head of':0.20, 'board':0.30,\n",
    "    'stakeholder':0.20, 'investor':0.25, 'executive':0.25,\n",
    "}\n",
    "\n",
    "# Hard keywords that directly trigger Critical (regardless of deadline)\n",
    "# These are unambiguous emergency signals — not soft/accumulative ones\n",
    "HARD_RISK_KW    = {'breach','outage','incident','data loss','ransomware','exploit',\n",
    "                   'attack','vulnerability','corruption','sev1','sev2'}\n",
    "HARD_URGENCY_KW = {'immediately','right now','asap','blocker','sev1','sev2',\n",
    "                   'overdue','action required'}\n",
    "\n",
    "WEIGHTS = {'deadline':0.35, 'urgency':0.25, 'risk':0.20, 'customer':0.12, 'authority':0.08}\n",
    "\n",
    "# ─── Scoring helpers ─────────────────────────────────────────────────────────\n",
    "def _lex_score(text: str, lex: Dict[str, float]) -> float:\n",
    "    \"\"\"Sum all matched keyword weights, capped at 1.0.\"\"\"    \n",
    "    low = text.lower()\n",
    "    return min(1.0, sum(w for k, w in lex.items() if k in low))\n",
    "\n",
    "def _deadline_proximity(deadline: Optional[datetime], anchor: datetime) -> float:\n",
    "    \"\"\"Map time-to-deadline → [0, 1]. Closer = higher score.\"\"\"    \n",
    "    if deadline is None: return 0.0\n",
    "    h = (ensure_ist(deadline) - ensure_ist(anchor)).total_seconds() / 3600\n",
    "    if h <= 0:    return 1.00   # overdue\n",
    "    if h <= 4:    return 0.95   # same-day critical\n",
    "    if h <= 24:   return 0.80   # today / tonight\n",
    "    if h <= 72:   return 0.55   # within 3 days\n",
    "    if h <= 168:  return 0.30   # within 1 week\n",
    "    return 0.10                 # > 1 week\n",
    "\n",
    "def _has_any(text: str, keywords: set) -> bool:\n",
    "    low = text.lower()\n",
    "    return any(k in low for k in keywords)\n",
    "\n",
    "# ─── Main priority function ───────────────────────────────────────────────────\n",
    "def compute_priority(\n",
    "    evidence: str,\n",
    "    deadline: Optional[datetime],\n",
    "    anchor: datetime,\n",
    "    context: str = '',\n",
    ") -> Tuple[str, float, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Two-stage priority model.\n",
    "\n",
    "    Stage 1 — Deadline floor\n",
    "      The deadline alone establishes the *minimum* label:\n",
    "        h ≤ 120h (5 days) → High\n",
    "        h ≤ 168h (7 days) → Medium\n",
    "        h > 168h or None  → Low\n",
    "\n",
    "    Stage 2 — Signal-based upgrades\n",
    "      Hard signals upgrade any floor to Critical:\n",
    "        • Hard urgency keyword  (immediately, asap, blocker, sev1/2, ...)\n",
    "        • Hard risk keyword     (breach, outage, incident, data loss, ...)\n",
    "        • Soft urgency + near-term (h ≤ 72h or no deadline) + risk ≥ 0.25\n",
    "        • Soft urgency + near-term (h ≤ 72h or no deadline) + authority ≥ 0.25\n",
    "\n",
    "      Soft urgency word on its own upgrades Medium → High.\n",
    "\n",
    "      Strong context (customer ≥ 0.40 or risk ≥ 0.40) upgrades floor to High\n",
    "      when a deadline exists (captures client/audit tasks with far deadlines).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    evidence  : task's evidence sentence\n",
    "    deadline  : normalized IST deadline (or None)\n",
    "    anchor    : email/summary date anchor for proximity scoring\n",
    "    context   : additional keywords (e.g. 'cfo sev1 client') applied to all lexicons\n",
    "    \"\"\"\n",
    "    full = evidence + ' ' + context\n",
    "\n",
    "    urgency  = _lex_score(full, URGENCY_LEX)\n",
    "    risk     = _lex_score(full, RISK_LEX)\n",
    "    customer = _lex_score(full, CUSTOMER_LEX)\n",
    "    authority= _lex_score(full, AUTHORITY_LEX)\n",
    "    dl_prox  = _deadline_proximity(deadline, anchor)\n",
    "\n",
    "    # Weighted score (for display/explainability only; label derived by rules below)\n",
    "    total = round(min(1.0, max(0.0,\n",
    "        WEIGHTS['deadline']*dl_prox + WEIGHTS['urgency']*urgency +\n",
    "        WEIGHTS['risk']*risk + WEIGHTS['customer']*customer + WEIGHTS['authority']*authority\n",
    "    )), 4)\n",
    "\n",
    "    # ── Stage 1: deadline-based floor ────────────────────────────────────────\n",
    "    if deadline is not None:\n",
    "        h = (ensure_ist(deadline) - ensure_ist(anchor)).total_seconds() / 3600\n",
    "        floor = 'High' if h <= 120 else ('Medium' if h <= 168 else 'Low')\n",
    "    else:\n",
    "        h     = None\n",
    "        floor = 'Low'\n",
    "\n",
    "    # ── Stage 2: Critical upgrades (hard signals only) ───────────────────────\n",
    "    near_term        = h is None or h <= 72\n",
    "    hard_risk        = _has_any(full, HARD_RISK_KW)\n",
    "    hard_urg         = _has_any(full, HARD_URGENCY_KW)\n",
    "    soft_urg_present = 'urgent' in full.lower() or 'critical' in full.lower()\n",
    "    soft_urg_risk    = soft_urg_present and risk     >= 0.25 and near_term\n",
    "    soft_urg_auth    = soft_urg_present and authority >= 0.25 and near_term\n",
    "\n",
    "    is_critical = hard_risk or hard_urg or soft_urg_risk or soft_urg_auth\n",
    "\n",
    "    # ── Stage 3: Strong context can raise floor to High ───────────────────────\n",
    "    strong_ctx = customer >= 0.40 or risk >= 0.40\n",
    "    if strong_ctx and deadline is not None:\n",
    "        floor = max(floor, 'High', key=lambda x: PRIORITY_ORDER[x])\n",
    "\n",
    "    # ── Stage 4: Soft urgency bumps Medium → High ────────────────────────────\n",
    "    if soft_urg_present and floor == 'Medium':\n",
    "        floor = 'High'\n",
    "\n",
    "    # ── Final label ──────────────────────────────────────────────────────────\n",
    "    label = 'Critical' if is_critical else floor\n",
    "\n",
    "    return label, total, {'deadline':dl_prox, 'urgency':urgency, 'risk':risk,\n",
    "                          'customer':customer, 'authority':authority, 'total':total}\n",
    "\n",
    "# ─── Demo ─────────────────────────────────────────────────────────────────────\n",
    "_anc = ensure_ist(datetime(2026, 2, 15, 10, 0))\n",
    "_pcases = [\n",
    "    # (evidence, deadline, context, expected)\n",
    "    ('Please send the invoice to finance by EOD today.',\n",
    "     ensure_ist(datetime(2026,2,15,18)), '', 'High'),\n",
    "    ('Urgent: finalize the month-end accruals by tomorrow 3pm.',\n",
    "     ensure_ist(datetime(2026,2,16,15)), 'cfo finance', 'Critical'),\n",
    "    ('SEV1: rollback the last deployment immediately and confirm status.',\n",
    "     None, 'production outage sev1', 'Critical'),\n",
    "    ('Investigate possible credential breach and share findings by tomorrow 10am.',\n",
    "     ensure_ist(datetime(2026,2,16,10)), 'security breach', 'Critical'),\n",
    "    ('Please update the internal wiki with deployment notes when convenient.',\n",
    "     None, '', 'Low'),\n",
    "    ('Collect 3 quotations and finalize the rate contract renewal by 2026-02-20.',\n",
    "     ensure_ist(datetime(2026,2,20,17)), '', 'Medium'),\n",
    "    ('Urgent: apply the critical security patch on prod-web-01 by EOD today.',\n",
    "     ensure_ist(datetime(2026,2,15,18)), 'security it ops', 'Critical'),\n",
    "    ('Upload audit evidence for Q4 controls by next Friday COB.',\n",
    "     ensure_ist(datetime(2026,2,20,17)), 'compliance audit regulatory', 'High'),\n",
    "    ('Complete threat model review for the new feature by Friday — urgent request from CTO.',\n",
    "     ensure_ist(datetime(2026,2,20,17)), 'cto security', 'High'),\n",
    "    ('Rotate production database credentials immediately. Security incident response.',\n",
    "     None, 'security breach production', 'Critical'),\n",
    "]\n",
    "print(f\"{'Evidence':<55} {'Exp':<10} {'Got':<10} {'Score':>6}  Components\")\n",
    "print('-'*115)\n",
    "all_ok = True\n",
    "for ev, dl, ctx, exp in _pcases:\n",
    "    lbl, score, bd = compute_priority(ev, dl, _anc, context=ctx)\n",
    "    ok = lbl == exp\n",
    "    if not ok: all_ok = False\n",
    "    parts = ' '.join(f'{k}={v:.2f}' for k,v in bd.items() if k != 'total')\n",
    "    mark = 'OK' if ok else 'FAIL'\n",
    "    print(f\"  {mark}  {ev[:50]:<50} {exp:<10} {lbl:<10} {score:>6.3f}  {parts}\")\n",
    "print()\n",
    "print(\"All priority tests passed.\" if all_ok else \"WARNING: some tests FAILED.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9 — End-to-End Pipeline: `extract_tasks(summary_text)`\n",
    "\n",
    "Assembles all modules into one function:\n",
    "1. Segment → detect task sentences (rule + KPE)\n",
    "2. For each candidate: NER → KPE → action → assignee → deadline → priority\n",
    "3. Deduplicate (token-F1 ≥ 0.88 = same task)\n",
    "4. Sort: priority DESC, confidence DESC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_tasks() pipeline ready.\n"
     ]
    }
   ],
   "source": [
    "def _rerank_by_relative_deadline(tasks: List['Task'], anchor: datetime) -> List['Task']:\n",
    "    \"\"\"\n",
    "    Post-process priority labels using relative deadline ordering within the task set.\n",
    "\n",
    "    Absolute deadline floors are calibrated for corporate/same-day emails.\n",
    "    For announcements or event-driven summaries where all deadlines are weeks away,\n",
    "    the absolute floors all collapse to Low, losing the relative urgency signal.\n",
    "\n",
    "    This function restores that signal by comparing each task's deadline to the\n",
    "    soonest deadline in the set:\n",
    "\n",
    "      - Attendance tasks (action contains 'report' and deadline has an explicit clock\n",
    "        time, e.g. 9:00 AM) -> upgraded to at least High.  These represent physical\n",
    "        presence obligations whose consequence (missing the event) is high-impact.\n",
    "\n",
    "      - Tasks whose deadline falls within 72 h of the soonest deadline in the set\n",
    "        -> upgraded to at least Medium.\n",
    "\n",
    "      - Tasks more than 72 h beyond the soonest deadline -> label left unchanged.\n",
    "\n",
    "    Rules:\n",
    "      * Only upgrades labels - never downgrades an existing High or Critical.\n",
    "      * Only activates when the set contains >= 2 tasks with deadlines, so\n",
    "        single-task summaries and all 30 benchmark test cases are unaffected.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tasks  : deduped task list (priority already set by compute_priority)\n",
    "    anchor : IST anchor datetime used for the same extract_tasks() call\n",
    "    \"\"\"\n",
    "    tasks_with_dl = [t for t in tasks if t.deadline is not None]\n",
    "    if len(tasks_with_dl) < 2:\n",
    "        return tasks   # no relative context - return unchanged\n",
    "\n",
    "    hours = {\n",
    "        id(t): (ensure_ist(t.deadline) - ensure_ist(anchor)).total_seconds() / 3600\n",
    "        for t in tasks_with_dl\n",
    "    }\n",
    "    soonest_h = min(hours.values())\n",
    "\n",
    "    for t in tasks_with_dl:\n",
    "        h   = hours[id(t)]\n",
    "        rel = h - soonest_h\n",
    "\n",
    "        # Attendance obligation: action contains 'report' with a non-default deadline\n",
    "        # time (17:00 / 18:00 are COB defaults; any other hour = explicitly stated)\n",
    "        is_attendance = (\n",
    "            'report' in t.action.lower() and\n",
    "            ensure_ist(t.deadline).hour not in (17, 18)\n",
    "        )\n",
    "        if is_attendance:\n",
    "            t.priority = max(t.priority, 'High', key=lambda x: PRIORITY_ORDER[x])\n",
    "            t.priority_breakdown['rerank_reason'] = 'attendance (explicit time)'\n",
    "\n",
    "        # Within 72 h of the soonest deadline -> at least Medium\n",
    "        if rel <= 72:\n",
    "            t.priority = max(t.priority, 'Medium', key=lambda x: PRIORITY_ORDER[x])\n",
    "            if 'rerank_reason' not in t.priority_breakdown:\n",
    "                t.priority_breakdown['rerank_reason'] = f'rel_gap={rel:.0f}h (<=72h from soonest)'\n",
    "        # else: keep current label - do not touch\n",
    "\n",
    "    return tasks\n",
    "\n",
    "def _token_f1(a: str, b: str) -> float:\n",
    "    sa = {w for w in a.lower().split() if w not in STOPWORDS}\n",
    "    sb = {w for w in b.lower().split() if w not in STOPWORDS}\n",
    "    if not sa or not sb: return 0.0\n",
    "    inter = len(sa & sb)\n",
    "    return 2 * inter / (len(sa) + len(sb))\n",
    "\n",
    "def extract_tasks(\n",
    "    summary_text: str,\n",
    "    anchor: Optional[datetime] = None,\n",
    "    context: str = '',\n",
    "    confidence_threshold: float = 0.35,\n",
    ") -> List[Task]:\n",
    "    \"\"\"\n",
    "    Main entry point.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    summary_text        : extractive or abstractive summary as plain text\n",
    "    anchor              : date anchor for deadline normalization (default: now_ist())\n",
    "    context             : optional extra text (e.g. email subject/keywords)\n",
    "                          for authority and customer impact scoring\n",
    "    confidence_threshold: min combined rule+KPE score to consider a sentence\n",
    "    \"\"\"\n",
    "    if anchor is None: anchor = now_ist()\n",
    "    anchor = ensure_ist(anchor)\n",
    "\n",
    "    sentences  = segment_sentences(summary_text)\n",
    "    candidates = detect_task_sentences(sentences, confidence_threshold)\n",
    "\n",
    "    tasks: List[Task] = []\n",
    "\n",
    "    for cand in candidates:\n",
    "        sent = cand['sentence']\n",
    "        kps  = cand['keyphrases']\n",
    "\n",
    "        # NER ─────────────────────────────────────────────────────────────────\n",
    "        ner = run_ner(sent)\n",
    "\n",
    "        # Action (multi-split if compound) ────────────────────────────────────\n",
    "        action_list = split_multi_actions(sent, kps)\n",
    "\n",
    "        # Assignee ────────────────────────────────────────────────────────────\n",
    "        assignee = pick_assignee(ner, sent)\n",
    "\n",
    "        # Deadline ────────────────────────────────────────────────────────────\n",
    "        # Augment sentence with spaCy DATE/TIME entities for better phrase matching\n",
    "        dl_text = sent\n",
    "        if ner.get('DATE'): dl_text += ' ' + ' '.join(ner['DATE'])\n",
    "        if ner.get('TIME'): dl_text += ' ' + ' '.join(ner['TIME'])\n",
    "        deadline, _ = extract_deadline(dl_text, anchor)\n",
    "\n",
    "        # Priority ────────────────────────────────────────────────────────────\n",
    "        pr_label, pr_score, pr_bd = compute_priority(sent, deadline, anchor, context=context)\n",
    "\n",
    "        # Build Task objects ──────────────────────────────────────────────────\n",
    "        sent_conf = cand['final_score']\n",
    "        for act in action_list:\n",
    "            if not act or len(act.split()) < 2: continue\n",
    "            task_conf = round(0.60 * sent_conf + 0.40 * pr_score, 3)\n",
    "            tasks.append(Task(\n",
    "                action             = act,\n",
    "                assignee           = assignee,\n",
    "                deadline           = deadline,\n",
    "                priority           = pr_label,\n",
    "                confidence         = task_conf,\n",
    "                keyphrases         = kps[:4],\n",
    "                ner_entities       = ner,\n",
    "                evidence_sentence  = sent,\n",
    "                priority_breakdown = pr_bd,\n",
    "            ))\n",
    "\n",
    "    # Deduplicate ─────────────────────────────────────────────────────────────\n",
    "    deduped: List[Task] = []\n",
    "    for t in sorted(tasks, key=lambda x: x.confidence, reverse=True):\n",
    "        if not any(_token_f1(t.action, u.action) >= 0.88 for u in deduped):\n",
    "            deduped.append(t)\n",
    "\n",
    "    # Re-rank by relative deadline within this task set ────────────────────────\n",
    "    deduped = _rerank_by_relative_deadline(deduped, anchor)\n",
    "\n",
    "    # Recompute confidence using final priority label ─────────────────────────\n",
    "    # Before re-ranking, task_conf used raw pr_score (a weighted-sum float ≈ 0.035\n",
    "    # for plain institutional emails).  After re-ranking the label may have been\n",
    "    # upgraded (Low → High), but conf still reflected the old pr_score, creating\n",
    "    # a contradiction (High priority, 33% confidence).  We fix that here by\n",
    "    # mapping the final label to a numeric anchor and reblending with sent_conf.\n",
    "    PRIORITY_CONF = {'Low': 0.10, 'Medium': 0.40, 'High': 0.70, 'Critical': 1.00}\n",
    "    for _t in deduped:\n",
    "        _raw_total = _t.priority_breakdown.get('total', 0.0)\n",
    "        _sent_conf = (_t.confidence - 0.40 * _raw_total) / 0.60  # recover sent_conf\n",
    "        _pri_num   = PRIORITY_CONF.get(_t.priority, 0.10)\n",
    "        _t.confidence = round(min(0.99, max(0.05, 0.60 * _sent_conf + 0.40 * _pri_num)), 3)\n",
    "\n",
    "    # Sort: priority DESC then confidence DESC ────────────────────────────────\n",
    "    deduped.sort(\n",
    "        key=lambda x: (PRIORITY_ORDER.get(x.priority, 1), x.confidence),\n",
    "        reverse=True\n",
    "    )\n",
    "    return deduped\n",
    "\n",
    "print('extract_tasks() pipeline ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10 — Demo: Full Pipeline on a Corporate Email Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TASK EXTRACTION RESULTS   (9 tasks found)\n",
      "Anchor: 2026-02-15T10:00:00+05:30\n",
      "======================================================================\n",
      "  +-- Task 1  [High] ████\n",
      "  |  Action     : raise a JIRA ticket\n",
      "  |  Assignee   : JIRA\n",
      "  |  Deadline   : 2026-02-15T18:00:00+05:30\n",
      "  |  Confidence : 65%\n",
      "  |  Keyphrases : jira ticket eod, raise jira, eod today, raise\n",
      "  |  NER PERSON  : JIRA\n",
      "  |  NER ORG     : EOD\n",
      "  |  NER DATE    : today\n",
      "  |  Evidence   : and raise a JIRA ticket by EOD today.\n",
      "  |  Score      : total=0.508  (deadline=0.80  urgency=0.00  risk=0.40  customer=0.80  authority=0.65)\n",
      "  +--------------------------------------------------------------\n",
      "\n",
      "  +-- Task 2  [High] ████\n",
      "  |  Action     : fix wednesday escalate\n",
      "  |  Assignee   : (unassigned)\n",
      "  |  Deadline   : 2026-02-18T17:00:00+05:30\n",
      "  |  Confidence : 61%\n",
      "  |  Keyphrases : fix wednesday escalate, fix wednesday, wednesday escalate, wednesday\n",
      "  |  NER DATE    : Wednesday\n",
      "  |  Evidence   : If the fix cannot be done by Wednesday, escalate\n",
      "  |  Score      : total=0.396  (deadline=0.30  urgency=0.25  risk=0.40  customer=0.80  authority=0.65)\n",
      "  +--------------------------------------------------------------\n",
      "\n",
      "  +-- Task 3  [High] ████\n",
      "  |  Action     : share the revised project timeline with stakeholders\n",
      "  |  Assignee   : Rahul\n",
      "  |  Deadline   : 2026-02-16T17:00:00+05:30\n",
      "  |  Confidence : 59%\n",
      "  |  Keyphrases : rahul share revised, project timeline stakeholders, stakeholders tomorrow, share revised project\n",
      "  |  NER ORG     : Rahul\n",
      "  |  NER DATE    : tomorrow\n",
      "  |  NER TIME    : pm\n",
      "  |  Evidence   : Rahul to share the revised project timeline with stakeholders by tomorrow 5pm.\n",
      "  |  Score      : total=0.436  (deadline=0.55  urgency=0.00  risk=0.40  customer=0.80  authority=0.85)\n",
      "  +--------------------------------------------------------------\n",
      "\n",
      "  +-- Task 4  [High] ████\n",
      "  |  Action     : complete the mandatory security awareness training\n",
      "  |  Assignee   : (unassigned)\n",
      "  |  Deadline   : 2026-02-27T17:00:00+05:30\n",
      "  |  Confidence : 48%\n",
      "  |  Keyphrases : security awareness training, complete mandatory security, team members complete, training end week\n",
      "  |  NER DATE    : end of next week\n",
      "  |  Evidence   : All team members must complete the mandatory security awareness training by end ...\n",
      "  |  Score      : total=0.313  (deadline=0.10  urgency=0.00  risk=0.65  customer=0.80  authority=0.65)\n",
      "  +--------------------------------------------------------------\n",
      "\n",
      "  +-- Task 5  [High] ████\n",
      "  |  Action     : data processing agreements\n",
      "  |  Assignee   : (unassigned)\n",
      "  |  Deadline   : 2026-02-20T17:00:00+05:30\n",
      "  |  Confidence : 46%\n",
      "  |  Keyphrases : data processing agreements, agreements friday, legal team review, review data\n",
      "  |  NER DATE    : next Friday\n",
      "  |  Evidence   : with the legal team to review the data processing agreements by next Friday.\n",
      "  |  Score      : total=0.373  (deadline=0.30  urgency=0.00  risk=0.60  customer=0.80  authority=0.65)\n",
      "  +--------------------------------------------------------------\n",
      "\n",
      "  +-- Task 6  [Low] ░░\n",
      "  |  Action     : upload all audit evidence documents to the SharePoint folder and coordinate\n",
      "  |  Assignee   : Carol\n",
      "  |  Deadline   : (not specified)\n",
      "  |  Confidence : 62%\n",
      "  |  Keyphrases : carol upload audit, upload audit evidence, audit evidence, evidence documents sharepoint\n",
      "  |  NER PERSON  : Carol\n",
      "  |  Evidence   : Carol must upload all audit evidence documents to the SharePoint folder and coor...\n",
      "  |  Score      : total=0.252  (deadline=0.00  urgency=0.00  risk=0.40  customer=0.80  authority=0.95)\n",
      "  +--------------------------------------------------------------\n",
      "\n",
      "  +-- Task 7  [Low] ░░\n",
      "  |  Action     : finalize the API integration test cases\n",
      "  |  Assignee   : Alice\n",
      "  |  Deadline   : (not specified)\n",
      "  |  Confidence : 57%\n",
      "  |  Keyphrases : api integration test, share test report, alice needs finalize, finalize api\n",
      "  |  NER PERSON  : Alice\n",
      "  |  Evidence   : Alice needs to finalize the API integration test cases and share the test report\n",
      "  |  Score      : total=0.228  (deadline=0.00  urgency=0.00  risk=0.40  customer=0.80  authority=0.65)\n",
      "  +--------------------------------------------------------------\n",
      "\n",
      "  +-- Task 8  [Low] ░░\n",
      "  |  Action     : share test report\n",
      "  |  Assignee   : Alice\n",
      "  |  Deadline   : (not specified)\n",
      "  |  Confidence : 57%\n",
      "  |  Keyphrases : api integration test, share test report, alice needs finalize, finalize api\n",
      "  |  NER PERSON  : Alice\n",
      "  |  Evidence   : Alice needs to finalize the API integration test cases and share the test report\n",
      "  |  Score      : total=0.228  (deadline=0.00  urgency=0.00  risk=0.40  customer=0.80  authority=0.65)\n",
      "  +--------------------------------------------------------------\n",
      "\n",
      "  +-- Task 9  [Low] ░░\n",
      "  |  Action     : investigate the root cause of the memory leak in the staging environment\n",
      "  |  Assignee   : Bob\n",
      "  |  Deadline   : (not specified)\n",
      "  |  Confidence : 51%\n",
      "  |  Keyphrases : memory leak staging, cause memory leak, root cause memory, bob investigate root\n",
      "  |  NER PERSON  : Bob\n",
      "  |  Evidence   : Bob, please investigate the root cause of the memory leak in the staging environ...\n",
      "  |  Score      : total=0.228  (deadline=0.00  urgency=0.00  risk=0.40  customer=0.80  authority=0.65)\n",
      "  +--------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DEMO_SUMMARY = \"\"\"\n",
    "Alice needs to finalize the API integration test cases and share the test report\n",
    "by Wednesday 3pm. This is critical as the client demo is scheduled for Thursday morning.\n",
    "\n",
    "Bob, please investigate the root cause of the memory leak in the staging environment\n",
    "and raise a JIRA ticket by EOD today. If the fix cannot be done by Wednesday, escalate\n",
    "to the CTO immediately.\n",
    "\n",
    "Carol must upload all audit evidence documents to the SharePoint folder and coordinate\n",
    "with the legal team to review the data processing agreements by next Friday.\n",
    "This is a mandatory regulatory compliance requirement.\n",
    "\n",
    "All team members must complete the mandatory security awareness training by end of next week.\n",
    "\n",
    "Rahul to share the revised project timeline with stakeholders by tomorrow 5pm.\n",
    "\"\"\"\n",
    "\n",
    "DEMO_CONTEXT = 'client delivery compliance audit CTO board SLA'\n",
    "DEMO_ANCHOR  = ensure_ist(datetime(2026, 2, 15, 10, 0))\n",
    "\n",
    "tasks = extract_tasks(DEMO_SUMMARY, anchor=DEMO_ANCHOR, context=DEMO_CONTEXT)\n",
    "\n",
    "print('=' * 70)\n",
    "print(f'TASK EXTRACTION RESULTS   ({len(tasks)} tasks found)')\n",
    "print(f'Anchor: {iso_ist(DEMO_ANCHOR)}')\n",
    "print('=' * 70)\n",
    "for i, t in enumerate(tasks, 1):\n",
    "    display_task(t, i)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11 — Structured JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"action\": \"raise a JIRA ticket\",\n",
      "    \"assignee\": \"JIRA\",\n",
      "    \"deadline\": \"2026-02-15T18:00:00+05:30\",\n",
      "    \"priority\": \"High\",\n",
      "    \"confidence\": 0.649,\n",
      "    \"evidence\": \"and raise a JIRA ticket by EOD today.\"\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"fix wednesday escalate\",\n",
      "    \"assignee\": null,\n",
      "    \"deadline\": \"2026-02-18T17:00:00+05:30\",\n",
      "    \"priority\": \"High\",\n",
      "    \"confidence\": 0.609,\n",
      "    \"evidence\": \"If the fix cannot be done by Wednesday, escalate\"\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"share the revised project timeline with stakeholders\",\n",
      "    \"assignee\": \"Rahul\",\n",
      "    \"deadline\": \"2026-02-16T17:00:00+05:30\",\n",
      "    \"priority\": \"High\",\n",
      "    \"confidence\": 0.59,\n",
      "    \"evidence\": \"Rahul to share the revised project timeline with stakeholders by tomorrow 5pm.\"\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"complete the mandatory security awareness training\",\n",
      "    \"assignee\": null,\n",
      "    \"deadline\": \"2026-02-27T17:00:00+05:30\",\n",
      "    \"priority\": \"High\",\n",
      "    \"confidence\": 0.485,\n",
      "    \"evidence\": \"All team members must complete the mandatory security awareness training by end of next week.\"\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"data processing agreements\",\n",
      "    \"assignee\": null,\n",
      "    \"deadline\": \"2026-02-20T17:00:00+05:30\",\n",
      "    \"priority\": \"High\",\n",
      "    \"confidence\": 0.455,\n",
      "    \"evidence\": \"with the legal team to review the data processing agreements by next Friday.\"\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"upload all audit evidence documents to the SharePoint folder and coordinate\",\n",
      "    \"assignee\": \"Carol\",\n",
      "    \"deadline\": null,\n",
      "    \"priority\": \"Low\",\n",
      "    \"confidence\": 0.62,\n",
      "    \"evidence\": \"Carol must upload all audit evidence documents to the SharePoint folder and coordinate\"\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"finalize the API integration test cases\",\n",
      "    \"assignee\": \"Alice\",\n",
      "    \"deadline\": null,\n",
      "    \"priority\": \"Low\",\n",
      "    \"confidence\": 0.567,\n",
      "    \"evidence\": \"Alice needs to finalize the API integration test cases and share the test report\"\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"share test report\",\n",
      "    \"assignee\": \"Alice\",\n",
      "    \"deadline\": null,\n",
      "    \"priority\": \"Low\",\n",
      "    \"confidence\": 0.567,\n",
      "    \"evidence\": \"Alice needs to finalize the API integration test cases and share the test report\"\n",
      "  },\n",
      "  {\n",
      "    \"action\": \"investigate the root cause of the memory leak in the staging environment\",\n",
      "    \"assignee\": \"Bob\",\n",
      "    \"deadline\": null,\n",
      "    \"priority\": \"Low\",\n",
      "    \"confidence\": 0.512,\n",
      "    \"evidence\": \"Bob, please investigate the root cause of the memory leak in the staging environment\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "output = [{\n",
    "    'action':    t.action,\n",
    "    'assignee':  t.assignee,\n",
    "    'deadline':  iso_ist(t.deadline),\n",
    "    'priority':  t.priority,\n",
    "    'confidence': t.confidence,\n",
    "    'evidence':  t.evidence_sentence,\n",
    "} for t in tasks]\n",
    "\n",
    "print(json.dumps(output, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12 — Evaluation Metrics\n",
    "\n",
    "- **detection_metrics:** Precision / Recall / F1 (task-level; token-F1 ≥ 0.60 = match)\n",
    "- **field_accuracy:** per-field accuracy on matched pairs (assignee, deadline ±2h, priority)\n",
    "- **strict_em:** 1.0 only if every task matches on all fields simultaneously\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions ready: detection_metrics(), field_accuracy(), strict_em()\n"
     ]
    }
   ],
   "source": [
    "def detection_metrics(gold: List[Dict], pred: List[Task]) -> Dict:\n",
    "    gold_acts = [g['action'] for g in gold]\n",
    "    matched, tp = set(), 0\n",
    "    for p in pred:\n",
    "        best_j, best_s = None, 0.0\n",
    "        for j, ga in enumerate(gold_acts):\n",
    "            if j in matched: continue\n",
    "            s = _token_f1(p.action, ga)\n",
    "            if s > best_s: best_s, best_j = s, j\n",
    "        if best_j is not None and best_s >= 0.60:\n",
    "            tp += 1; matched.add(best_j)\n",
    "    fp = max(0, len(pred) - tp)\n",
    "    fn = max(0, len(gold) - tp)\n",
    "    p_, r_ = tp/max(1,tp+fp), tp/max(1,tp+fn)\n",
    "    return {'tp':tp,'fp':fp,'fn':fn,'precision':round(p_,3),'recall':round(r_,3),\n",
    "            'f1':round(2*p_*r_/(p_+r_) if (p_+r_) else 0.0, 3)}\n",
    "\n",
    "def field_accuracy(gold: List[Dict], pred: List[Task]) -> Dict:\n",
    "    used, asgn, ddl, pri = set(), [], [], []\n",
    "    def norm(x): return re.sub(r'\\s+', ' ', str(x or '').split('@')[0]).strip().lower()\n",
    "    for g in gold:\n",
    "        best_i, best_s = None, 0.0\n",
    "        for i, p in enumerate(pred):\n",
    "            if i in used: continue\n",
    "            s = _token_f1(p.action, g['action'])\n",
    "            if s > best_s: best_s, best_i = s, i\n",
    "        if best_i is None: continue\n",
    "        used.add(best_i); p = pred[best_i]\n",
    "        asgn.append(1.0 if norm(g.get('assignee')) == norm(p.assignee) else 0.0)\n",
    "        gd  = g.get('deadline_iso')\n",
    "        gdt = ensure_ist(datetime.fromisoformat(gd)) if gd else None\n",
    "        if gdt is None and p.deadline is None: ddl.append(1.0)\n",
    "        elif gdt is None or p.deadline is None: ddl.append(0.0)\n",
    "        else: ddl.append(1.0 if abs((ensure_ist(p.deadline)-gdt).total_seconds())<=7200 else 0.0)\n",
    "        pri.append(1.0 if (g.get('priority') or 'Medium') == p.priority else 0.0)\n",
    "    avg = lambda xs: round(sum(xs)/max(1,len(xs)), 3)\n",
    "    return {'assignee_acc':avg(asgn), 'deadline_acc':avg(ddl), 'priority_acc':avg(pri)}\n",
    "\n",
    "def strict_em(gold: List[Dict], pred: List[Task]) -> float:\n",
    "    if len(gold) != len(pred): return 0.0\n",
    "    used = set()\n",
    "    def norm(x): return re.sub(r'\\s+', ' ', str(x or '').split('@')[0]).strip().lower()\n",
    "    for g in gold:\n",
    "        found = False\n",
    "        for i, p in enumerate(pred):\n",
    "            if i in used: continue\n",
    "            a_ok  = _token_f1(p.action, g['action']) >= 0.85\n",
    "            as_ok = norm(p.assignee) == norm(g.get('assignee'))\n",
    "            pr_ok = p.priority == (g.get('priority') or 'Medium')\n",
    "            gd    = g.get('deadline_iso')\n",
    "            gdt   = ensure_ist(datetime.fromisoformat(gd)) if gd else None\n",
    "            d_ok  = (gdt is None and p.deadline is None) or (\n",
    "                gdt and p.deadline and abs((ensure_ist(p.deadline)-gdt).total_seconds())<=7200)\n",
    "            if a_ok and as_ok and pr_ok and d_ok:\n",
    "                used.add(i); found = True; break\n",
    "        if not found: return 0.0\n",
    "    return 1.0\n",
    "\n",
    "print('Evaluation functions ready: detection_metrics(), field_accuracy(), strict_em()')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13 — 30 Gold-Standard Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 test cases loaded.\n"
     ]
    }
   ],
   "source": [
    "def _iso(y,mo,d,hh=17,mi=0): return iso_ist(ensure_ist(datetime(y,mo,d,hh,mi)))\n",
    "BASE = ensure_ist(datetime(2026, 2, 15, 10, 0))\n",
    "\n",
    "TESTCASES = [\n",
    "  {\"id\":1,\"summary\":\"Please send the invoice to finance by EOD today.\",\n",
    "   \"anchor\":BASE,\"context\":\"\",\n",
    "   \"gold\":[{\"action\":\"send the invoice to finance\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,15,18),\"priority\":\"High\"}]},\n",
    "  {\"id\":2,\"summary\":\"Urgent: finalize the month-end accruals by tomorrow 3pm.\",\n",
    "   \"anchor\":BASE,\"context\":\"cfo finance\",\n",
    "   \"gold\":[{\"action\":\"finalize the month-end accruals\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,16,15),\"priority\":\"Critical\"}]},\n",
    "  {\"id\":3,\"summary\":\"Neha, please raise the PO for laptop procurement before Friday.\",\n",
    "   \"anchor\":BASE,\"context\":\"\",\n",
    "   \"gold\":[{\"action\":\"raise the PO for laptop procurement\",\"assignee\":\"Neha\",\"deadline_iso\":_iso(2026,2,19,17),\"priority\":\"High\"}]},\n",
    "  {\"id\":4,\"summary\":\"Process the refund for order #88421 within 24 hours. This is high priority.\",\n",
    "   \"anchor\":BASE,\"context\":\"\",\n",
    "   \"gold\":[{\"action\":\"process the refund for order #88421\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,16,10),\"priority\":\"High\"}]},\n",
    "  {\"id\":5,\"summary\":\"Neha, urgent: ensure your team completes compliance training by EOD today.\",\n",
    "   \"anchor\":BASE,\"context\":\"compliance hr\",\n",
    "   \"gold\":[{\"action\":\"ensure your team completes compliance training\",\"assignee\":\"Neha\",\"deadline_iso\":_iso(2026,2,15,18),\"priority\":\"High\"}]},\n",
    "  {\"id\":6,\"summary\":\"Rahul, please submit performance feedback for Ankit by tomorrow 11am.\",\n",
    "   \"anchor\":BASE,\"context\":\"\",\n",
    "   \"gold\":[{\"action\":\"submit performance feedback for Ankit\",\"assignee\":\"Rahul\",\"deadline_iso\":_iso(2026,2,16,11),\"priority\":\"High\"}]},\n",
    "  {\"id\":7,\"summary\":\"Urgent: apply the critical security patch on prod-web-01 by EOD today.\",\n",
    "   \"anchor\":BASE,\"context\":\"security it ops\",\n",
    "   \"gold\":[{\"action\":\"apply the critical security patch on prod-web-01\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,15,18),\"priority\":\"Critical\"}]},\n",
    "  {\"id\":8,\"summary\":\"Deploy release v2.4.1 to staging today 7pm and share sanity results.\",\n",
    "   \"anchor\":BASE,\"context\":\"\",\n",
    "   \"gold\":[{\"action\":\"deploy release v2.4.1 to staging\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,15,19),\"priority\":\"High\"}]},\n",
    "  {\"id\":9,\"summary\":\"SEV1: rollback the last deployment immediately and confirm status.\",\n",
    "   \"anchor\":BASE,\"context\":\"production outage sev1\",\n",
    "   \"gold\":[{\"action\":\"rollback the last deployment\",\"assignee\":None,\"deadline_iso\":None,\"priority\":\"Critical\"}]},\n",
    "  {\"id\":10,\"summary\":\"Investigate possible credential breach and share findings by tomorrow 10am.\",\n",
    "   \"anchor\":BASE,\"context\":\"security breach\",\n",
    "   \"gold\":[{\"action\":\"investigate possible credential breach\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,16,10),\"priority\":\"Critical\"}]},\n",
    "  {\"id\":11,\"summary\":\"Neha, please send the customer communication draft within 2 hours.\",\n",
    "   \"anchor\":BASE,\"context\":\"client customer\",\n",
    "   \"gold\":[{\"action\":\"send the customer communication draft\",\"assignee\":\"Neha\",\"deadline_iso\":_iso(2026,2,15,12),\"priority\":\"High\"}]},\n",
    "  {\"id\":12,\"summary\":\"Rahul, prepare the demo deck and share with Client Orion before Friday.\",\n",
    "   \"anchor\":BASE,\"context\":\"client delivery\",\n",
    "   \"gold\":[{\"action\":\"prepare the demo deck and share with Client Orion\",\"assignee\":\"Rahul\",\"deadline_iso\":_iso(2026,2,19,17),\"priority\":\"High\"}]},\n",
    "  {\"id\":13,\"summary\":\"Verify UAT defect fixes on staging and confirm status by tomorrow 1pm.\",\n",
    "   \"anchor\":BASE,\"context\":\"client qa\",\n",
    "   \"gold\":[{\"action\":\"verify UAT defect fixes on staging\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,16,13),\"priority\":\"High\"}]},\n",
    "  {\"id\":14,\"summary\":\"Priya, please update the MoM with decisions and circulate by today 6pm.\",\n",
    "   \"anchor\":BASE,\"context\":\"\",\n",
    "   \"gold\":[{\"action\":\"update the MoM with decisions and circulate\",\"assignee\":\"Priya\",\"deadline_iso\":_iso(2026,2,15,18),\"priority\":\"High\"}]},\n",
    "  {\"id\":15,\"summary\":\"Complete threat model review for the new feature by Friday — urgent request from CTO.\",\n",
    "   \"anchor\":BASE,\"context\":\"cto security\",\n",
    "   \"gold\":[{\"action\":\"complete threat model review for the new feature\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,20,17),\"priority\":\"High\"}]},\n",
    "  {\"id\":16,\"summary\":\"Review the liability clause and revert with comments by EOD today. High priority legal requirement.\",\n",
    "   \"anchor\":BASE,\"context\":\"legal compliance\",\n",
    "   \"gold\":[{\"action\":\"review the liability clause and revert with comments\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,15,18),\"priority\":\"High\"}]},\n",
    "  {\"id\":17,\"summary\":\"Rahul to share revised timeline by tomorrow 5pm. Priya to schedule client sync call by Monday.\",\n",
    "   \"anchor\":BASE,\"context\":\"client\",\n",
    "   \"gold\":[{\"action\":\"share revised timeline\",\"assignee\":\"Rahul\",\"deadline_iso\":_iso(2026,2,16,17),\"priority\":\"High\"},\n",
    "            {\"action\":\"schedule client sync call\",\"assignee\":\"Priya\",\"deadline_iso\":_iso(2026,2,16,17),\"priority\":\"High\"}]},\n",
    "  {\"id\":18,\"summary\":\"Collect 3 quotations and finalize the rate contract renewal by 2026-02-20.\",\n",
    "   \"anchor\":BASE,\"context\":\"\",\n",
    "   \"gold\":[{\"action\":\"collect 3 quotations and finalize the rate contract renewal\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,20,17),\"priority\":\"Medium\"}]},\n",
    "  {\"id\":19,\"summary\":\"Please coordinate MFA rollout for the finance team by next Friday.\",\n",
    "   \"anchor\":BASE,\"context\":\"security it\",\n",
    "   \"gold\":[{\"action\":\"coordinate MFA rollout for the finance team\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,20,17),\"priority\":\"Medium\"}]},\n",
    "  {\"id\":20,\"summary\":\"Schedule the postmortem meeting for next Friday 3pm and share invite with the team.\",\n",
    "   \"anchor\":BASE,\"context\":\"\",\n",
    "   \"gold\":[{\"action\":\"schedule the postmortem meeting\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,20,15),\"priority\":\"Medium\"}]},\n",
    "  {\"id\":21,\"summary\":\"Urgent: fix the backup failure on db-prod-02 immediately. Production data at risk.\",\n",
    "   \"anchor\":BASE,\"context\":\"production data loss\",\n",
    "   \"gold\":[{\"action\":\"fix the backup failure on db-prod-02\",\"assignee\":None,\"deadline_iso\":None,\"priority\":\"Critical\"}]},\n",
    "  {\"id\":22,\"summary\":\"Review the MSA draft and share comments by tomorrow EOD.\",\n",
    "   \"anchor\":BASE,\"context\":\"legal vendor\",\n",
    "   \"gold\":[{\"action\":\"review the MSA draft and share comments\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,16,18),\"priority\":\"High\"}]},\n",
    "  {\"id\":23,\"summary\":\"Process advance payment of INR 250000 for supplier Alpha by today 4pm. Urgent request.\",\n",
    "   \"anchor\":BASE,\"context\":\"finance billing\",\n",
    "   \"gold\":[{\"action\":\"process advance payment of INR 250000 for supplier Alpha\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,15,16),\"priority\":\"High\"}]},\n",
    "  {\"id\":24,\"summary\":\"Respond to the customer escalation email within 4 hours. SLA breach risk.\",\n",
    "   \"anchor\":BASE,\"context\":\"customer sla client\",\n",
    "   \"gold\":[{\"action\":\"respond to the customer escalation email\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,15,14),\"priority\":\"Critical\"}]},\n",
    "  {\"id\":25,\"summary\":\"Complete the go-live checklist and confirm sign-off by Friday COB.\",\n",
    "   \"anchor\":BASE,\"context\":\"go-live client delivery\",\n",
    "   \"gold\":[{\"action\":\"complete the go-live checklist and confirm sign-off\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,20,17),\"priority\":\"High\"}]},\n",
    "  {\"id\":26,\"summary\":\"Upload audit evidence for Q4 controls by next Friday COB. Compliance deadline.\",\n",
    "   \"anchor\":BASE,\"context\":\"compliance audit regulatory\",\n",
    "   \"gold\":[{\"action\":\"upload audit evidence for Q4 controls\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,20,17),\"priority\":\"High\"}]},\n",
    "  {\"id\":27,\"summary\":\"Shortlist candidates and share interview slots with the manager by tomorrow noon.\",\n",
    "   \"anchor\":BASE,\"context\":\"\",\n",
    "   \"gold\":[{\"action\":\"shortlist candidates and share interview slots\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,16,12),\"priority\":\"High\"}]},\n",
    "  {\"id\":28,\"summary\":\"Rotate production database credentials immediately. Security incident response.\",\n",
    "   \"anchor\":BASE,\"context\":\"security breach production\",\n",
    "   \"gold\":[{\"action\":\"rotate production database credentials\",\"assignee\":None,\"deadline_iso\":None,\"priority\":\"Critical\"}]},\n",
    "  {\"id\":29,\"summary\":\"Draft release notes for v2.4.1 and send to client by EOD today.\",\n",
    "   \"anchor\":BASE,\"context\":\"client delivery\",\n",
    "   \"gold\":[{\"action\":\"draft release notes for v2.4.1 and send to client\",\"assignee\":None,\"deadline_iso\":_iso(2026,2,15,18),\"priority\":\"High\"}]},\n",
    "  {\"id\":30,\"summary\":\"Blocker: client reporting is down. Fix and restore service immediately. Production SLA breach.\",\n",
    "   \"anchor\":BASE,\"context\":\"production client sla outage\",\n",
    "   \"gold\":[{\"action\":\"fix and restore service\",\"assignee\":None,\"deadline_iso\":None,\"priority\":\"Critical\"}]},\n",
    "]\n",
    "\n",
    "assert len(TESTCASES) == 30\n",
    "print(f'30 test cases loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14 — Benchmark Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      " BENCHMARK  (30 test cases | anchor: Asia/Kolkata IST)\n",
      "========================================================================\n",
      "  Detection Precision      0.850  █████████████████████████░░░░░\n",
      "  Detection Recall         1.000  ██████████████████████████████\n",
      "  Detection F1             0.900  ███████████████████████████░░░\n",
      "  Assignee Accuracy        0.833  ████████████████████████░░░░░░\n",
      "  Deadline Accuracy        0.900  ███████████████████████████░░░\n",
      "  Priority Accuracy        0.933  ███████████████████████████░░░\n",
      "  Strict EM                0.467  ██████████████░░░░░░░░░░░░░░░░\n",
      "\n",
      "ERROR BREAKDOWN:\n",
      "  false_positive      :   9  (32.1%)\n",
      "  missed_task         :   0  (0.0%)\n",
      "  coref_error         :   5  (17.9%)\n",
      "  temporal_error      :   3  (10.7%)\n",
      "  span_mismatch       :   9  (32.1%)\n",
      "  priority_error      :   2  (7.1%)\n"
     ]
    }
   ],
   "source": [
    "all_det, all_fa, all_em = [], [], []\n",
    "errors = {'false_positive':0,'missed_task':0,'coref_error':0,\n",
    "          'temporal_error':0,'span_mismatch':0,'priority_error':0}\n",
    "\n",
    "for tc in TESTCASES:\n",
    "    pred = extract_tasks(tc['summary'], anchor=tc['anchor'], context=tc.get('context',''))\n",
    "    gold = tc['gold']\n",
    "    all_det.append(detection_metrics(gold, pred))\n",
    "    all_fa.append(field_accuracy(gold, pred))\n",
    "    all_em.append(strict_em(gold, pred))\n",
    "\n",
    "    # per-test error breakdown\n",
    "    used = set()\n",
    "    for g in gold:\n",
    "        best_i, best_s = None, 0.0\n",
    "        for i, p in enumerate(pred):\n",
    "            if i in used: continue\n",
    "            s = _token_f1(p.action, g['action'])\n",
    "            if s > best_s: best_s, best_i = s, i\n",
    "        if best_i is None or best_s < 0.60:\n",
    "            errors['missed_task'] += 1; continue\n",
    "        used.add(best_i); p = pred[best_i]\n",
    "        if best_s < 0.85: errors['span_mismatch'] += 1\n",
    "        def norm(x): return str(x or '').split('@')[0].strip().lower()\n",
    "        if norm(g.get('assignee')) != norm(p.assignee): errors['coref_error'] += 1\n",
    "        gd  = g.get('deadline_iso')\n",
    "        gdt = ensure_ist(datetime.fromisoformat(gd)) if gd else None\n",
    "        if gdt and p.deadline and abs((ensure_ist(p.deadline)-gdt).total_seconds())>7200:\n",
    "            errors['temporal_error'] += 1\n",
    "        elif bool(gdt) != bool(p.deadline):\n",
    "            errors['temporal_error'] += 1\n",
    "        if (g.get('priority') or 'Medium') != p.priority:\n",
    "            errors['priority_error'] += 1\n",
    "    errors['false_positive'] += all_det[-1]['fp']\n",
    "\n",
    "def avg(lst, k): return round(sum(m[k] for m in lst)/len(lst), 3)\n",
    "\n",
    "print()\n",
    "print('=' * 72)\n",
    "print(f' BENCHMARK  ({len(TESTCASES)} test cases | anchor: Asia/Kolkata IST)')\n",
    "print('=' * 72)\n",
    "metrics = [\n",
    "    ('Detection Precision',  avg(all_det, 'precision')),\n",
    "    ('Detection Recall',     avg(all_det, 'recall')),\n",
    "    ('Detection F1',         avg(all_det, 'f1')),\n",
    "    ('Assignee Accuracy',    avg(all_fa,  'assignee_acc')),\n",
    "    ('Deadline Accuracy',    avg(all_fa,  'deadline_acc')),\n",
    "    ('Priority Accuracy',    avg(all_fa,  'priority_acc')),\n",
    "    ('Strict EM',            round(sum(all_em)/len(all_em), 3)),\n",
    "]\n",
    "for name, val in metrics:\n",
    "    bar = chr(9608)*int(val*30) + chr(9617)*(30-int(val*30))\n",
    "    print(f'  {name:<24} {val:.3f}  {bar}')\n",
    "print()\n",
    "print('ERROR BREAKDOWN:')\n",
    "total_e = max(1, sum(errors.values()))\n",
    "for k, v in errors.items():\n",
    "    print(f'  {k:<20}: {v:3d}  ({100*v/total_e:.1f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 15 — Interactive Tester\n",
    "\n",
    "Paste any email summary into `MY_SUMMARY` and run this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_SUMMARY = \"\"\"\n",
    "Annual Strategy Workshop will be held from March 18th to March 20th at Chavara Hall, RSET Campus. \n",
    "Participants are requested to report by 9:00 AM on March 18th. \n",
    "The proposed consolidated budget for the upcoming initiatives is $45,000. \n",
    "Lunch and refreshments will be provided during the sessions. \n",
    "Kindly submit your department presentations by March 10th. \n",
    "Any revisions must be completed before March 15th. \n",
    "If you are unable to attend the workshop, please inform HR by March 12th. \n",
    "The workshop sessions will begin at 9:30 AM each day and conclude by 4:30 PM. \n",
    "The conference is open to the entire campus community.\n",
    "\"\"\"\n",
    "\n",
    "MY_ANCHOR  = now_ist()                        # use current time as anchor\n",
    "MY_CONTEXT = ''                               # no extra authority/customer keywords for this workshop email\n",
    "\n",
    "out = extract_tasks(MY_SUMMARY, anchor=MY_ANCHOR, context=MY_CONTEXT)\n",
    "\n",
    "print(f'Extracted {len(out)} tasks:\\n')\n",
    "for i, t in enumerate(out, 1):\n",
    "    display_task(t, i)\n",
    "    print()\n",
    "\n",
    "print('JSON:')\n",
    "print(json.dumps([{\n",
    "    'action': t.action, 'assignee': t.assignee,\n",
    "    'deadline': iso_ist(t.deadline), 'priority': t.priority,\n",
    "    'confidence': t.confidence,\n",
    "} for t in out], indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 16 — Task Filtering: `filter_tasks_for_user()`\n",
    "\n",
    "Filters the output of `extract_tasks()` to only the tasks that are relevant\n",
    "to a specific user, identified by their name.\n",
    "\n",
    "**Filtering rules (applied *after* full extraction + prioritisation)**\n",
    "\n",
    "| Condition | Decision |\n",
    "|-----------|----------|\n",
    "| `assignee` is `None` or empty | ✅ Include — unassigned / broadcast task |\n",
    "| `assignee` is a generic collective (`Participants`, `Team`, `All`, `Everyone`, …) | ✅ Include |\n",
    "| `assignee` matches user by first name, last name, full name, or title+last | ✅ Include |\n",
    "| `assignee` is a specific person/org that is **not** the user | ❌ Exclude |\n",
    "\n",
    "> This cell is self-contained so `task_filter.py` (used by the FastAPI\n",
    "> service) can mirror the exact same logic without any circular dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re as _re\n",
    "\n",
    "# ── Generic / collective assignee labels ──────────────────────────────────────\n",
    "# Mirrors COLLECTIVE_ACTORS (Cell 5) plus additional broadcast phrases.\n",
    "# All comparisons are lower-cased.\n",
    "_GENERIC_ASSIGNEES = frozenset({\n",
    "    \"participants\", \"attendees\",\n",
    "    \"all team members\", \"all staff\", \"all employees\", \"all users\",\n",
    "    \"team members\", \"department heads\", \"departments\", \"all participants\",\n",
    "    \"everyone\", \"team\", \"all\", \"staff\", \"recipients\", \"colleagues\", \"members\",\n",
    "})\n",
    "\n",
    "_TITLE_PREFIX_RE = _re.compile(r\"^(?:mr|mrs|ms|miss|dr|prof)\\.?\\s+\", _re.IGNORECASE)\n",
    "\n",
    "\n",
    "def _is_generic_assignee(assignee: str) -> bool:\n",
    "    \"\"\"Return True if assignee is a collective / broadcast label.\"\"\"\n",
    "    return assignee.lower().strip() in _GENERIC_ASSIGNEES\n",
    "\n",
    "\n",
    "def _assignee_matches_user(assignee: str,\n",
    "                            first_name: str,   # lower-cased\n",
    "                            last_name:  str,   # lower-cased, may be \"\"\n",
    "                            full_name:  str,   # lower-cased\n",
    "                           ) -> bool:\n",
    "    \"\"\"\n",
    "    Case-insensitive name match.  Handles:\n",
    "      - First name only         e.g. \"Elena\"\n",
    "      - Last name only          e.g. \"Smith\"\n",
    "      - Full display name       e.g. \"Elena Smith\"\n",
    "      - Title + last name       e.g. \"Ms. Smith\", \"Mr Smith\", \"Dr. Smith\"\n",
    "    \"\"\"\n",
    "    a = assignee.lower().strip()\n",
    "    a_no_title = _TITLE_PREFIX_RE.sub(\"\", a).strip()\n",
    "    return (\n",
    "        a == first_name\n",
    "        or (last_name and a == last_name)\n",
    "        or (full_name and a == full_name)\n",
    "        or (last_name and a_no_title == last_name)\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_tasks_for_user(\n",
    "    tasks: List[Task],\n",
    "    user_first_name:   str,\n",
    "    user_last_name:    str,\n",
    "    user_display_name: str,\n",
    ") -> List[Task]:\n",
    "    \"\"\"\n",
    "    Return only the tasks from *tasks* that are relevant to the given user.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tasks             : full output of extract_tasks()\n",
    "    user_first_name   : first name  (e.g. \"Elena\")\n",
    "    user_last_name    : last name   (e.g. \"Smith\")  — pass \"\" if unavailable\n",
    "    user_display_name : full display name  (e.g. \"Elena Smith\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Filtered list preserving the original priority / confidence order.\n",
    "    \"\"\"\n",
    "    fn   = user_first_name.lower().strip()\n",
    "    ln   = user_last_name.lower().strip()\n",
    "    full = user_display_name.lower().strip()\n",
    "\n",
    "    def _keep(t: Task) -> bool:\n",
    "        if not t.assignee:\n",
    "            return True    # unassigned → broadcast, include always\n",
    "        if _is_generic_assignee(t.assignee):\n",
    "            return True    # collective label → include\n",
    "        if _assignee_matches_user(t.assignee, fn, ln, full):\n",
    "            return True    # name match → include\n",
    "        return False       # someone else's task → exclude\n",
    "\n",
    "    return [t for t in tasks if _keep(t)]\n",
    "\n",
    "\n",
    "print(\"filter_tasks_for_user() ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 17 — Filtering Demo\n",
    "\n",
    "Demonstrates `filter_tasks_for_user()` using the `tasks` list produced by\n",
    "**Cell 10** (the corporate email demo).\n",
    "\n",
    "That email has tasks assigned to: Alice, Bob, Carol, Rahul, and All team members.\n",
    "We simulate three different logged-in users and show what each one sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires Cell 10 (tasks variable) and Cell 32 (filter_tasks_for_user) to have run.\n",
    "\n",
    "_demo_users = [\n",
    "    # (display_name,   first_name, last_name)\n",
    "    (\"Alice Johnson\",  \"alice\",    \"johnson\"),   # has specific tasks + generic tasks\n",
    "    (\"Bob Chen\",       \"bob\",      \"chen\"),      # has specific tasks + generic tasks\n",
    "    (\"Elena Smith\",    \"elena\",    \"smith\"),     # not in email → only generic tasks\n",
    "]\n",
    "\n",
    "for _display, _fn, _ln in _demo_users:\n",
    "    _filtered = filter_tasks_for_user(\n",
    "        tasks             = tasks,\n",
    "        user_first_name   = _fn,\n",
    "        user_last_name    = _ln,\n",
    "        user_display_name = _display,\n",
    "    )\n",
    "    print(f\"\\n{'='*62}\")\n",
    "    print(f\"  User : {_display}\")\n",
    "    print(f\"  Sees : {len(_filtered)} / {len(tasks)} tasks\")\n",
    "    print(f\"{'='*62}\")\n",
    "    for _i, _t in enumerate(_filtered, 1):\n",
    "        _bar = {\"Low\":\"░░\",\"Medium\":\"▒▒▒\",\"High\":\"████\",\"Critical\":\"██████\"}.get(_t.priority,\"\")\n",
    "        _asgn = f\"assignee={_t.assignee!r}\" if _t.assignee else \"unassigned\"\n",
    "        print(f\"  {_i}. [{_t.priority}] {_bar}  {_t.action[:52]:<52}  ({_asgn})\")\n",
    "    if not _filtered:\n",
    "        print(\"  (no tasks for this user in this email)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
